{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from google.cloud import storage\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes e funções necessáriaspara o funcionamento do código:\n",
    "def verificacao_texto(data_frame, coluna, tamanho_texto: None, numeros: bool):\n",
    "    '''\n",
    "    Função para identificar problemas em colunas que contenham apenas letras e números\n",
    "    '''\n",
    "    problemas = []\n",
    "    for i in range(len(data_frame)):\n",
    "        texto = str(data_frame.loc[i, coluna])\n",
    "        if numeros == False:\n",
    "            if texto.isalpha() == False:\n",
    "                problemas.append(data_frame.loc[i, coluna])\n",
    "            elif tamanho_texto != None:\n",
    "                if len(texto) != tamanho_texto:\n",
    "                    problemas.append(data_frame.loc[i, coluna])\n",
    "        elif numeros == True:\n",
    "            if texto.isalnum() == False:\n",
    "                problemas.append(data_frame.loc[i, coluna])\n",
    "            elif tamanho_texto != None:\n",
    "                if len(texto) != tamanho_texto:\n",
    "                    problemas.append(data_frame.loc[i, coluna])\n",
    "    # Imprimindo os problemas que deverão ser corrigidos:\n",
    "    df_problemas = pd.DataFrame(problemas, columns=[\"corrigir\"])\n",
    "    df_problemas = pd.DataFrame(df_problemas.corrigir.unique(), columns=[\"Corrigir:\"])\n",
    "\n",
    "    if len(df_problemas) > 0:\n",
    "        print(df_problemas)\n",
    "    else:\n",
    "        print(\"Nenhum problema detectado nesta coluna\")\n",
    "    print(f\"Verificação da coluna {coluna} concluída\")\n",
    "\n",
    "\n",
    "def verificacao_tipo(data_frame, coluna, tipo: type):\n",
    "    '''\n",
    "    Função para verificar problemas relacionado ao tipo de dados que a coluna deve possuir\n",
    "    '''\n",
    "    problemas = []\n",
    "    for i in range(len(data_frame)):\n",
    "        try:\n",
    "            tipo(data_frame.loc[i, coluna])\n",
    "        except Exception:\n",
    "            problemas.append(data_frame.loc[i, coluna])\n",
    "    df_problemas = pd.DataFrame(problemas, columns=[\"corrigir\"])\n",
    "    df_problemas = pd.DataFrame(df_problemas.corrigir.unique(), columns=[\"Corrigir: \"])\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    print(f\"Verificando a coluna {coluna}: \")\n",
    "    if len(df_problemas) > 0:\n",
    "        print(df_problemas)\n",
    "    else:\n",
    "        print(\"Nenhum problema detectado nessa coluna\")\n",
    "    print(f\"Verificação da coluna {coluna} concluída\")\n",
    "    return df_problemas\n",
    "\n",
    "\n",
    "def verificacao_valor_padrao(data_frame, coluna):\n",
    "    '''\n",
    "    Função para identificar os valores únicos presentes em uma coluna, útil para caso de colunas que possuem valores padronizados, como por exemplo 'SIM' e 'NÃO'\n",
    "    '''\n",
    "    unicos = data_frame[coluna].unique()\n",
    "    print(\"---------------------------------------------------------------------\")\n",
    "    print(f\"Verificando valores únicos da coluna {coluna}: \")\n",
    "    print(unicos)\n",
    "    print(\"Verificação concluída\")\n",
    "\n",
    "\n",
    "def verificacao_data(data_frame, coluna, formato: str):\n",
    "    '''\n",
    "    Função para verificar se todos os valores de uma coluna correspondem a data do formato especificado\n",
    "    '''\n",
    "    problemas = []\n",
    "    # Verificando se tratam-se de datas:\n",
    "    for i in range(len(data_frame)):\n",
    "        try:\n",
    "            datetime.now() - datetime.strptime(data_frame.loc[i, coluna], formato)\n",
    "        except Exception:\n",
    "            if data_frame.loc[i, coluna] != 'NULO':\n",
    "                problemas.append(data_frame.loc[i, coluna])\n",
    "    df_problemas = pd.DataFrame(problemas, columns=[\"Corrigir:\"])\n",
    "    print(\"---------------------------------------------------------------------\")\n",
    "    print(f\"Verificando a coluna {coluna}: \")\n",
    "    if len(df_problemas) > 0:\n",
    "        print(df_problemas)\n",
    "    else:\n",
    "        print(\"Não há nenhum problema para corrigir\")\n",
    "    print(f\"Verificação da coluna {coluna} concluída! \")\n",
    "\n",
    "class Conector_mysql:\n",
    "    def __init__(self, host, user, password, db):\n",
    "        self.host = host\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.db = db\n",
    "    \n",
    "    def envia_mysql(self, dfs, table):\n",
    "        self.dfs = dfs\n",
    "        self.table = table\n",
    "        self.dfs.write.format(\"jdbc\")\\\n",
    "                .option('url', f'jdbc:mysql://{self.host}/{self.db}')\\\n",
    "                .option('driver', 'com.mysql.cj.jdbc.Driver')\\\n",
    "                .option(\"numPartitions\", \"10\") \\\n",
    "                .option(\"user\",self.user)\\\n",
    "                .option(\"password\", self.password)\\\n",
    "                .option(\"dbtable\", self.db + \".\" + self.table)\\\n",
    "                .mode(\"append\").save()\n",
    "    \n",
    "    def ler_mysql(self, table, spark_conection):\n",
    "        self.table = table\n",
    "        self.spark_conection = spark_conection\n",
    "        self.df = self.spark_conection.read.format(\"jdbc\")\\\n",
    "            .option('url', f'jdbc:mysql://{self.host}/{self.db}')\\\n",
    "            .option('driver', 'com.mysql.cj.jdbc.Driver')\\\n",
    "            .option(\"user\",self.user)\\\n",
    "            .option(\"password\", self.password)\\\n",
    "            .option(\"dbtable\", self.db + \".\" + self.table).load()\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Conectando com a SpakSession\n",
    "'''\n",
    "\n",
    "spark = ( SparkSession.builder\n",
    "                        .master(\"local\")\n",
    "                        .appName(\"sparksql\")\n",
    "                        .config(\"spark.ui.port\", \"4050\")\n",
    "                        .config(\"spark.jars\", 'https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-hadoop2-latest.jar')\n",
    "                        .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando inconsistências da DF Arrecadacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectando com o mySQL\n",
    "conexao_mysql = Conector_mysql(\"34.72.50.43\", \"root\", \">}Dzh.=}YhZ#(G>s\", \"original\")\n",
    "\n",
    "# Puxando os dados do MySQL\n",
    "dfs_arrecadacao = conexao_mysql.ler_mysql('arrecadacao', spark)\n",
    "dfs_barragens = conexao_mysql.ler_mysql('barragens', spark)\n",
    "dfs_autuacao = conexao_mysql.ler_mysql('autuacao', spark)\n",
    "dfs_beneficiada = conexao_mysql.ler_mysql('beneficiada', spark)\n",
    "dfs_distribuicao = conexao_mysql.ler_mysql('distribuicao', spark)\n",
    "dfs_municipio = conexao_mysql.ler_mysql('municipio', spark)\n",
    "dfs_pib = conexao_mysql.ler_mysql('pib', spark)\n",
    "dfs_dados_populacao = conexao_mysql.ler_mysql('dados_populacao', spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando DataFrame Arrecadação Spark em DataFrame Pandas\n",
    "dfp_arrecadacao = dfs_arrecadacao.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1657294 entries, 0 to 1657293\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count    Dtype  \n",
      "---  ------                    --------------    -----  \n",
      " 0   index                     1657294 non-null  int64  \n",
      " 1   Ano                       1657294 non-null  int32  \n",
      " 2   Mês                       1657294 non-null  int32  \n",
      " 3   Processo                  1552074 non-null  float64\n",
      " 4   AnoDoProcesso             1552074 non-null  float64\n",
      " 5   Tipo_PF_PJ                1657294 non-null  object \n",
      " 6   CPF_CNPJ                  1657208 non-null  object \n",
      " 7   Substância                1657294 non-null  object \n",
      " 8   UF                        1655722 non-null  object \n",
      " 9   Município                 1655722 non-null  object \n",
      " 10  QuantidadeComercializada  1642254 non-null  object \n",
      " 11  UnidadeDeMedida           1656589 non-null  object \n",
      " 12  ValorRecolhido            1657294 non-null  object \n",
      "dtypes: float64(2), int32(2), int64(1), object(8)\n",
      "memory usage: 151.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Analisando dados\n",
    "dfp_arrecadacao.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                            0\n",
       "Ano                              0\n",
       "Mês                              0\n",
       "Processo                    105220\n",
       "AnoDoProcesso               105220\n",
       "Tipo_PF_PJ                       0\n",
       "CPF_CNPJ                        86\n",
       "Substância                       0\n",
       "UF                            1572\n",
       "Município                     1572\n",
       "QuantidadeComercializada     15040\n",
       "UnidadeDeMedida                705\n",
       "ValorRecolhido                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_arrecadacao.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_arrecadacao.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012,\n",
       "       2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_arrecadacao.Ano.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  5,  6,  7,  9, 10, 11, 12,  1,  2,  3,  4], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_arrecadacao.Mês.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Verificando a coluna Processo: \n",
      "   Corrigir: \n",
      "0         NaN\n",
      "Verificação da coluna Processo concluída\n",
      "  Corrigir:\n",
      "0         -\n",
      "Verificação da coluna Tipo_PF_PJ concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Substância: \n",
      "['BASALTO' 'AREIA' 'MINÉRIO DE FERRO' 'ARGILA P/CER. VERMELH'\n",
      " 'ÁGUA MINERAL' 'AREIA FINA' 'GRANITO P/ BRITA' 'FOLHELHO ARGILOSO'\n",
      " 'CALCÁRIO' 'CASCALHO' 'AREIA FLUVIAL' 'AREIA COMUM' 'BASALTO P/ BRITA'\n",
      " 'ÁGUA MINERAL ALC. BIC' 'ARGILA' 'QUARTZITO FRIÁVEL' 'MÁRMORE'\n",
      " 'ARGILA COMUM' 'GRANITO' 'FILITO' 'SAIBRO' 'BRITA DE GRANITO' 'NÍQUEL'\n",
      " 'AREIA LAVADA' 'CHARNOQUITO' 'ARGILA VERMELHA' 'BASALTO P/ REVESTIMENTO'\n",
      " 'FOSFATO' 'GIPSITA' 'QUARTZITO' 'ARGILA REFRATÁRIA' 'ARGILA CAULÍNICA'\n",
      " 'ARENITO' 'CALCÁRIO CALCÍTICO' 'GNAISSE P/ BRITA' 'MINÉRIO DE OURO'\n",
      " 'CAULIM' 'FELDSPATO' 'FONÓLITO' 'CALCÁRIO DOLOMÍTICO' 'PEDRA CALCÁRIA'\n",
      " 'PEDRA SÃO TOMÉ' 'ÁGUA POTÁVEL DE MESA' 'RIÓLITO' 'AREIA ALUVIONAR'\n",
      " 'QUARTZITO P/ REVESTIMENTO' 'SIENITO ORNAMENTAL' 'PEDRA QUARTZITO'\n",
      " 'AREIA DE BARRANCO' 'MANGANÊS' 'SEIXOS' 'FOLHELHO ARDOSIANO'\n",
      " 'DIABÁSIO P/ BRITA' 'LATERITA' 'TUFO VULCÂNICO' 'GIPSO' 'GRANITO AMARELO'\n",
      " 'AREIA IN NATURA' 'AREIA QUARTZOSA' 'DOLOMITO' 'GNAISSE' 'SEIXOS ROLADOS'\n",
      " 'AREIA P/ JATEAMENTO' 'MINÉRIO DE MANGANÊS' 'ILMENITA' 'RUTILO'\n",
      " 'ZIRCONITA' 'AMETISTA' 'SIENITO' 'CALCÁRIO P/ BRITA' 'ARDÓSIA'\n",
      " 'CARVÃO MINERAL' 'ÁGUA MINERAL ALC. TER. MAGNE' 'MÁRMORE INDUSTRIAL'\n",
      " 'GRANITO ORNAMENTAL' 'ÁGUAS TERMAIS' 'QUARTZITO SERICITICO' 'MICAXISTO'\n",
      " 'AGALMATOLITO' 'QUARTZITO INDUSTRIAL' 'ÁGUA GASOSA' 'DIABÁSIO' 'GRAFITA'\n",
      " 'BENTONITA' 'AREIA INDUSTRIAL' 'CIANITA' 'SALGEMA' 'OURO' 'BAUXITA'\n",
      " 'TURFA' 'MÁRMORE P/ REVESTIMENTO' 'SERICITA' 'TALCO' 'ESMERALDA'\n",
      " 'MINÉRIO DE URÂNIO' 'PIROCLORO' 'MAGNESITA' 'CROMITA'\n",
      " 'GRANITO P/ REVESTIMENTO' 'CASSITERITA' 'XISTO' 'MIGMATITO'\n",
      " 'CALCÁRIO FOSFOROSO' 'APATITA' 'ESTEATITO' 'VERMICULITA'\n",
      " 'ÁGUA MINERAL RAD. FON' 'CALCITA' 'ARGILITO' 'GRANODIORITO P/ BRITA'\n",
      " 'QUARTZO' 'DIATOMITA' 'ALEXANDRITA' 'LEUCOFILITO' 'DIORITO ORNAMENTAL'\n",
      " 'CONCHAS CALCÁRIAS' 'ROCHA CALCÁRIA' 'XISTO BETUMINOSO' 'FERRO'\n",
      " 'GRANULITO' 'DIATOMITO' 'BARITA' 'AMIANTO' 'ARGILA LEUCÍTICA' 'SAPONITO'\n",
      " 'MINÉRIO DE ZINCO' 'TINGUAÍTO' 'SERPENTINITO' 'PRATA' 'ESPODUMÊNIO'\n",
      " 'PIRITA' 'LEUCITA' 'CALCÁRIO INDUSTRIAL' 'DIORITO' 'MIGMATITO P/ BRITA'\n",
      " 'FLUORITA' 'SAIS DE SÓDIO' 'ÁGUA MINERAL LITINADA' 'HEMATITA'\n",
      " 'ÁGUAS OLIGOMINERAIS' 'SILVITA' 'DUNITO' 'MINÉRIO DE NÍQUEL' 'COBRE'\n",
      " 'GRANODIORITO' 'AREIA DE FUNDIÇÃO' 'AREIA P/ VIDRO' 'MINÉRIO DE ALUMÍNIO'\n",
      " 'ROCHA FOSFÁTICA' 'DIORITO P/ BRITA' 'NEFELINA FONÓLITO' 'NEFELINA'\n",
      " 'ÁGUA MINERAL SULFUROS' 'SILTITO' 'SAIBREIRA' 'CARVÃO' 'ARGILA BRANCA'\n",
      " 'PEDREGULHO' 'ARGILA FERRUGINOSA' 'MICA' 'PEDRA CORADA'\n",
      " 'LATERITA FERRUGINOSA' 'TOPÁZIO IMPERIAL' 'MINÉRIO DE CHUMBO'\n",
      " 'QUARTZITO DUMORTIERITO' 'GNAISSE INDUSTRIAL' 'GRANITO VERDE UBATUBA'\n",
      " 'SIENITO P/ REVESTIMENTO' 'TANTALITA-COLUMBITA' 'ÁGATA'\n",
      " 'DIAMANTE INDUSTRIAL' 'PEGMATITO' 'TURMALINA' 'CASCALHO SILICOSO'\n",
      " 'CONGLOMERADO' 'SILÍCIO' 'OCRE' 'FERRO MANGANÊS' 'MINÉRIO DE TITÂNIO'\n",
      " 'CALCÁRIO MAGNESIANO' 'ALUMÍNIO' 'DIABÁSIO P/ REVESTIMENTO' 'PALÁDIO'\n",
      " 'GEMA' 'FERTILIZANTE FOSFATADO' 'ROCHA BETUMINOSA' 'GNAISSE ORNAMENTAL'\n",
      " 'ÁGUA MINERAL ALC. TER. CALCI.' 'ÁGUA TERMO MINERAL' 'SODALITA SIENITO'\n",
      " 'CAULIM ARGILOSO' 'VARVITO' 'DIAMANTE' 'MIGMATITO ORNAMENTAL' 'SODALITA'\n",
      " 'MINÉRIO DE COBRE' 'QUARTZO FUNDENTE' 'CALCÁRIO SEDIMENTAR' 'BARITINA'\n",
      " 'GNAISSE GRANÍTICO' 'NEFELINA SIENITO' 'GABRO' 'PEDRA SABÃO' 'GESSO'\n",
      " 'SIENITO INDUSTRIAL' 'QUARTZITO ROSA' 'GRANITO GNÁISSICO' 'CAULINITA'\n",
      " 'TAGUÁ' 'ÁGUA MINERAL ALC. TER' 'SÍLICA' 'WOLFRAMITA' 'MINÉRIO DE CROMO'\n",
      " 'AUGEN GNAISSE' 'COLUMBITA' 'GNAISSE P/ REVESTIMENTO'\n",
      " 'GRANODIORITO P/ REVESTIMENTO' 'BIOTITA GRANITO' 'OPALA' 'CROMO'\n",
      " 'QUARTZO INDUSTRIAL' 'AREIA SILICOSA' 'SCHEELITA' 'ALGAS CALCÁREAS'\n",
      " 'ARGILA BENTONÍTICA' 'ARGILA ALUMINOSA' 'MONAZITA' 'CATACLASITO'\n",
      " 'PEDRA PRECIOSA' 'CALCÁRIO BETUMINOSO' 'ÁGUA MARINHA' 'TOPÁZIO' 'CHUMBO'\n",
      " 'ÁGUA MINERAL CARBOGAS' 'URÂNIO' 'MINÉRIO DE ESTANHO' 'TERRAS RARAS'\n",
      " 'MONZOGRANITO' 'ESTANHO' 'SILICATOS DE ZINCO' 'ARGILA BAUXÍTICA' 'NIÓBIO'\n",
      " 'ANDALUZITA INDUSTRIAL' 'MINÉRIO DE PRATA' 'METACONGLOMERADO'\n",
      " 'PIROFILITA' 'CRISOTILA' 'TUFO' 'OURO NATIVO' 'SILEXITO'\n",
      " 'ALUVIÃO AURÍFERO' 'TANTALITA' 'CRISOBERILO' 'SIENO GRANITO' 'ZIRCÔNIO'\n",
      " 'MINÉRIO DE TUNGSTÊNIO' 'MINÉRIO DE LÍTIO' 'CASCALHO DIAMANTÍFERO'\n",
      " 'TUNGSTÊNIO' 'ANDESITO' 'MINÉRIO DE SILÍCIO' 'MINÉRIO DE ZIRCÔNIO'\n",
      " 'LEPIDOLITA' 'ARENITO INDUSTRIAL' 'MINÉRIO DE BERÍLIO' 'SILVINITA'\n",
      " 'SÍLEX' 'MUSCOVITA' 'MINÉRIO DE MOLIBDÊNIO' 'CALCÁRIO CONCHÍFERO'\n",
      " 'FOLHELHO' 'MINÉRIO DE NIÓBIO' 'XISTO ARGILOSO' 'MOSCOVITA'\n",
      " 'HIDRARGILITA' 'BERILO' 'MINÉRIO DE TÂNTALO' 'TONALITO'\n",
      " 'MÁRMORE DOLOMÍTICO' 'TRAQUITO' 'CARBONATITO' 'MAGNETITA' 'PETALITA'\n",
      " 'KUNZITA' 'BAUXITA FOSFOROSA' 'ZINCO' 'WILLEMITA' 'TÂNTALO' 'CANGA'\n",
      " 'CRISTAL DE ROCHA' 'TITÂNIO' 'SULFETOS DE CHUMBO' 'ROCHA POTÁSSICA'\n",
      " 'CALCEDÔNIA' 'GRANADA' 'CITRINO' 'SULFETOS DE NÍQUEL' 'COBALTO'\n",
      " 'QUARTZO COM INCLUSÕES' 'ALUVIÃO ESTANÍFERO' 'ATAPULGITA'\n",
      " 'MINÉRIO DE VANÁDIO' 'LIMONITA' 'MORGANITA' 'ARCÓSIO' 'DACITO'\n",
      " 'MONZONITO' 'DIOPSÍDIO' 'CORÍNDON' 'ANFIBÓLIO' 'PIROXENITO']\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna UF: \n",
      "['RS' 'GO' 'MG' 'BA' 'MS' 'SP' 'PE' 'SC' 'PR' 'CE' 'MT' 'RJ' 'RO' 'PI'\n",
      " 'RR' 'ES' 'PB' 'MA' 'PA' 'AM' 'TO' 'DF' 'AL' 'RN' 'AC' 'SE' 'AP' None]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Município: \n",
      "['TRÊS DE MAIO' 'SÃO LUÍS DE MONTES BELOS' 'CONGONHAS' ... 'BURITICUPU'\n",
      " 'PRESIDENTE VENCESLAU' 'MIRANTE DO PARANAPANEMA']\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna QuantidadeComercializada: \n",
      "['0' '141' '134144' ... '19479,87' '39600,93' '52387,33']\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna QuantidadeComercializada: \n",
      "['0' '141' '134144' ... '19479,87' '39600,93' '52387,33']\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna UnidadeDeMedida: \n",
      "['m3' 't' 'l' 'g' 'm2' 'kg' 'ct' None]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna ValorRecolhido: \n",
      "['206,41' '34,33' '33065,2' ... '1296,65' '19107,13' '25276,45']\n",
      "Verificação concluída\n"
     ]
    }
   ],
   "source": [
    "verificacao_tipo(dfp_arrecadacao, 'Processo', int)\n",
    "verificacao_texto(dfp_arrecadacao, 'Tipo_PF_PJ', None, False)\n",
    "verificacao_valor_padrao(dfp_arrecadacao, 'Substância')\n",
    "verificacao_valor_padrao(dfp_arrecadacao, 'UF')\n",
    "verificacao_valor_padrao(dfp_arrecadacao, 'Município')\n",
    "verificacao_valor_padrao(dfp_arrecadacao, 'QuantidadeComercializada')\n",
    "verificacao_valor_padrao(dfp_arrecadacao, 'QuantidadeComercializada')\n",
    "verificacao_valor_padrao(dfp_arrecadacao, 'UnidadeDeMedida')\n",
    "verificacao_valor_padrao(dfp_arrecadacao, 'ValorRecolhido')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamentos:\n",
    "dfp_arrecadacao.drop_duplicates()\n",
    "dfp_arrecadacao.replace(to_replace='ARGILA P/CER. VERMELH', value='ARGILA P/CER. VERMELHA', inplace=True)\n",
    "dfp_arrecadacao.replace(to_replace='-', value=np.nan, inplace=True)\n",
    "dfp_arrecadacao.fillna(np.nan)\n",
    "dfp_arrecadacao.replace(to_replace='None', value=np.nan, inplace=True)\n",
    "dfp_arrecadacao.drop(['CPF_CNPJ', 'index'], axis=1, inplace=True)\n",
    "dfp_arrecadacao['QuantidadeComercializada'] = dfp_arrecadacao['QuantidadeComercializada'].str.replace(',', '.')\n",
    "dfp_arrecadacao['ValorRecolhido'] = dfp_arrecadacao['ValorRecolhido'].str.replace(',', '.')\n",
    "dfp_arrecadacao['QuantidadeComercializada'] = dfp_arrecadacao['QuantidadeComercializada'].astype(float)\n",
    "dfp_arrecadacao['ValorRecolhido'] = dfp_arrecadacao['ValorRecolhido'].astype(float)\n",
    "dfp_arrecadacao['UnidadeDeMedida'].replace(to_replace='m3', value='Metros Cubicos', inplace=True)\n",
    "dfp_arrecadacao['UnidadeDeMedida'].replace(to_replace='t', value='Toneladas', inplace=True)\n",
    "dfp_arrecadacao['UnidadeDeMedida'].replace(to_replace='l', value='Litros', inplace=True)\n",
    "dfp_arrecadacao['UnidadeDeMedida'].replace(to_replace='g', value='Gramas', inplace=True)\n",
    "dfp_arrecadacao['UnidadeDeMedida'].replace(to_replace='m2', value='Metros Quadrados', inplace=True)\n",
    "dfp_arrecadacao['UnidadeDeMedida'].replace(to_replace='ct', value='Quilates', inplace=True)\n",
    "dfp_arrecadacao.replace(to_replace='OURO', value='MINÉRIO DE OURO', inplace=True)\n",
    "dfp_arrecadacao.replace(to_replace='FERRO', value='MINÉRIO DE FERRO', inplace=True)\n",
    "dfp_arrecadacao.replace(to_replace='COBRE', value='MINÉRIO DE COBRE', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando inconsistências na dataframe df_pib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando DataFrame PIB Spark em DataFrame Pandas\n",
    "dfp_pib = dfs_pib.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ano</th>\n",
       "      <th>id_municipio</th>\n",
       "      <th>pib</th>\n",
       "      <th>impostos_liquidos</th>\n",
       "      <th>va</th>\n",
       "      <th>va_agropecuaria</th>\n",
       "      <th>va_industria</th>\n",
       "      <th>va_servicos</th>\n",
       "      <th>va_adespss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>94616.000000</td>\n",
       "      <td>94616.000000</td>\n",
       "      <td>9.461600e+04</td>\n",
       "      <td>9.461600e+04</td>\n",
       "      <td>9.461600e+04</td>\n",
       "      <td>9.461600e+04</td>\n",
       "      <td>9.461600e+04</td>\n",
       "      <td>9.461600e+04</td>\n",
       "      <td>9.461600e+04</td>\n",
       "      <td>9.461600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>47307.500000</td>\n",
       "      <td>2010.003002</td>\n",
       "      <td>3.253181e+06</td>\n",
       "      <td>7.287343e+08</td>\n",
       "      <td>1.052315e+08</td>\n",
       "      <td>6.235028e+08</td>\n",
       "      <td>3.313567e+07</td>\n",
       "      <td>1.531836e+08</td>\n",
       "      <td>3.329723e+08</td>\n",
       "      <td>1.042113e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27313.430872</td>\n",
       "      <td>4.898931</td>\n",
       "      <td>9.844558e+05</td>\n",
       "      <td>8.059832e+09</td>\n",
       "      <td>1.489081e+09</td>\n",
       "      <td>6.596790e+09</td>\n",
       "      <td>6.356696e+07</td>\n",
       "      <td>1.094854e+09</td>\n",
       "      <td>4.885391e+09</td>\n",
       "      <td>1.058767e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>1.100015e+06</td>\n",
       "      <td>-1.904643e+07</td>\n",
       "      <td>-1.508840e+07</td>\n",
       "      <td>-5.105931e+08</td>\n",
       "      <td>-2.298910e+06</td>\n",
       "      <td>-2.897193e+09</td>\n",
       "      <td>3.722780e+05</td>\n",
       "      <td>1.446664e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23653.750000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>2.512101e+06</td>\n",
       "      <td>3.905784e+07</td>\n",
       "      <td>1.478442e+06</td>\n",
       "      <td>3.729948e+07</td>\n",
       "      <td>6.121093e+06</td>\n",
       "      <td>1.904200e+06</td>\n",
       "      <td>8.765398e+06</td>\n",
       "      <td>1.286555e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47307.500000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>3.146255e+06</td>\n",
       "      <td>8.971593e+07</td>\n",
       "      <td>4.477020e+06</td>\n",
       "      <td>8.467848e+07</td>\n",
       "      <td>1.519649e+07</td>\n",
       "      <td>6.322138e+06</td>\n",
       "      <td>2.362657e+07</td>\n",
       "      <td>2.568912e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70961.250000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>4.119103e+06</td>\n",
       "      <td>2.555032e+08</td>\n",
       "      <td>1.811785e+07</td>\n",
       "      <td>2.356625e+08</td>\n",
       "      <td>3.532677e+07</td>\n",
       "      <td>3.520165e+07</td>\n",
       "      <td>8.064128e+07</td>\n",
       "      <td>5.908990e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>94615.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>5.300108e+06</td>\n",
       "      <td>7.146834e+11</td>\n",
       "      <td>1.271543e+11</td>\n",
       "      <td>5.875291e+11</td>\n",
       "      <td>2.482540e+09</td>\n",
       "      <td>6.689305e+10</td>\n",
       "      <td>4.854288e+11</td>\n",
       "      <td>1.017928e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index           ano  id_municipio           pib  \\\n",
       "count  94616.000000  94616.000000  9.461600e+04  9.461600e+04   \n",
       "mean   47307.500000   2010.003002  3.253181e+06  7.287343e+08   \n",
       "std    27313.430872      4.898931  9.844558e+05  8.059832e+09   \n",
       "min        0.000000   2002.000000  1.100015e+06 -1.904643e+07   \n",
       "25%    23653.750000   2006.000000  2.512101e+06  3.905784e+07   \n",
       "50%    47307.500000   2010.000000  3.146255e+06  8.971593e+07   \n",
       "75%    70961.250000   2014.000000  4.119103e+06  2.555032e+08   \n",
       "max    94615.000000   2018.000000  5.300108e+06  7.146834e+11   \n",
       "\n",
       "       impostos_liquidos            va  va_agropecuaria  va_industria  \\\n",
       "count       9.461600e+04  9.461600e+04     9.461600e+04  9.461600e+04   \n",
       "mean        1.052315e+08  6.235028e+08     3.313567e+07  1.531836e+08   \n",
       "std         1.489081e+09  6.596790e+09     6.356696e+07  1.094854e+09   \n",
       "min        -1.508840e+07 -5.105931e+08    -2.298910e+06 -2.897193e+09   \n",
       "25%         1.478442e+06  3.729948e+07     6.121093e+06  1.904200e+06   \n",
       "50%         4.477020e+06  8.467848e+07     1.519649e+07  6.322138e+06   \n",
       "75%         1.811785e+07  2.356625e+08     3.532677e+07  3.520165e+07   \n",
       "max         1.271543e+11  5.875291e+11     2.482540e+09  6.689305e+10   \n",
       "\n",
       "        va_servicos    va_adespss  \n",
       "count  9.461600e+04  9.461600e+04  \n",
       "mean   3.329723e+08  1.042113e+08  \n",
       "std    4.885391e+09  1.058767e+09  \n",
       "min    3.722780e+05  1.446664e+06  \n",
       "25%    8.765398e+06  1.286555e+07  \n",
       "50%    2.362657e+07  2.568912e+07  \n",
       "75%    8.064128e+07  5.908990e+07  \n",
       "max    4.854288e+11  1.017928e+11  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_pib.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                0\n",
      "ano                  0\n",
      "id_municipio         0\n",
      "pib                  0\n",
      "impostos_liquidos    0\n",
      "va                   0\n",
      "va_agropecuaria      0\n",
      "va_industria         0\n",
      "va_servicos          0\n",
      "va_adespss           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dfp_pib.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_pib.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                int64\n",
      "ano                  int32\n",
      "id_municipio         int32\n",
      "pib                  int64\n",
      "impostos_liquidos    int64\n",
      "va                   int64\n",
      "va_agropecuaria      int64\n",
      "va_industria         int64\n",
      "va_servicos          int64\n",
      "va_adespss           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dfp_pib.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando inconsistências na DF Barragens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando Dataframe Barragens Spark em Dataframe Pandas\n",
    "dfp_barragens = dfs_barragens.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 906 entries, 0 to 905\n",
      "Data columns (total 95 columns):\n",
      " #   Column                                                            Non-Null Count  Dtype \n",
      "---  ------                                                            --------------  ----- \n",
      " 0   index                                                             906 non-null    int64 \n",
      " 1   ID                                                                906 non-null    int32 \n",
      " 2   Nome                                                              906 non-null    object\n",
      " 3   Empreendedor                                                      906 non-null    object\n",
      " 4   CPF_CNPJ                                                          906 non-null    object\n",
      " 5   UF                                                                906 non-null    object\n",
      " 6   Município                                                         906 non-null    object\n",
      " 7   Latitude                                                          906 non-null    object\n",
      " 8   Longitude                                                         906 non-null    object\n",
      " 9   Posicionamento                                                    906 non-null    object\n",
      " 10  Categoria de Risco - CRI                                          906 non-null    object\n",
      " 11  Dano Potencial Associado - DPA                                    906 non-null    object\n",
      " 12  Classe                                                            906 non-null    object\n",
      " 13  Necessita de PAEBM                                                906 non-null    object\n",
      " 14  Inserido na PNSB                                                  906 non-null    object\n",
      " 15  Nível de Emergência                                               906 non-null    object\n",
      " 16  Status da DCE Atual                                               906 non-null    object\n",
      " 17  Tipo de Barragem de Mineração                                     906 non-null    object\n",
      " 18  Barragem possui estrutura interna selante                         906 non-null    object\n",
      " 19  Quantidade Diques Internos                                        906 non-null    int32 \n",
      " 20  Quantidade Diques Selantes                                        906 non-null    int32 \n",
      " 21  A barragem de mineração possui Back Up Dam                        906 non-null    object\n",
      " 22  Esta Back Up Dam está operando pós rompimento da barragem         906 non-null    object\n",
      " 23  Nome da Back Up Dam                                               906 non-null    object\n",
      " 24  UF (Back Up Dam)                                                  906 non-null    object\n",
      " 25  Município (Back Up Dam)                                           906 non-null    object\n",
      " 26  Situação operacional da Back Up Dam                               906 non-null    object\n",
      " 27  Desde (Back Up Dam)                                               906 non-null    object\n",
      " 28  Vida útil prevista da Back Up Dam (Anos)                          906 non-null    object\n",
      " 29  Previsão de término de construção da Back Up Dam                  906 non-null    object\n",
      " 30  A BUD está em Área do Processo ANM ou da Área de Servidão         906 non-null    object\n",
      " 31  Processos associados (Back Up Dam)                                906 non-null    object\n",
      " 32  Posicionamento (Back Up Dam)                                      906 non-null    object\n",
      " 33  Latitude (Back Up Dam)                                            906 non-null    object\n",
      " 34  Longitude (Back Up Dam)                                           906 non-null    object\n",
      " 35  Altura Máxima do projeto da Back Up Dam (m)                       906 non-null    object\n",
      " 36  Comprimento da Crista do projeto da Back Up Dam (m)               906 non-null    object\n",
      " 37  Volume do projeto da Back Up Dam (m³)                             906 non-null    object\n",
      " 38  Descarga Máxima do vertedouro da Dack Up Dam (m³/seg)             906 non-null    object\n",
      " 39  Possui documentação de segurança com ART                          906 non-null    object\n",
      " 40  Existe manual de operação da Back Up Dam                          906 non-null    object\n",
      " 41  A Back up Dam passou por auditoria de terceira parte              906 non-null    object\n",
      " 42  BUD garante redução da área da mancha de inundação à jusante      906 non-null    object\n",
      " 43  Tipo de Back Up Dam quanto ao material de construção              906 non-null    object\n",
      " 44  Tipo de fundação da Back Up Dam                                   906 non-null    object\n",
      " 45  Vazão de projeto da Back Up Dam                                   906 non-null    object\n",
      " 46  Método construtivo da Back Up Dam                                 906 non-null    object\n",
      " 47  Tipo de auscultação da Back Up Dam                                906 non-null    object\n",
      " 48  Situação Operacional                                              906 non-null    object\n",
      " 49  Desde                                                             906 non-null    object\n",
      " 50  Vida útil prevista da Barragem (anos)                             906 non-null    object\n",
      " 51  Estrutura com o Objetivo de Contenção                             906 non-null    object\n",
      " 52  Está dentro da Área do Processo ANM ou da Área de Servidão        906 non-null    object\n",
      " 53  Barragem de mineração é alimentado por usina                      906 non-null    object\n",
      " 54  Usinas                                                            906 non-null    object\n",
      " 55  Minério principal presente no reservatório                        906 non-null    object\n",
      " 56  Processo de beneficiamento                                        906 non-null    object\n",
      " 57  Produtos químicos utilizados                                      906 non-null    object\n",
      " 58  A Barragem armazena rejeitos/residuos que contenham Cianeto       906 non-null    object\n",
      " 59  Teor (%) do minério principal inserido no rejeito                 906 non-null    object\n",
      " 60  Outras substâncias minerais presentes no reservatório             906 non-null    object\n",
      " 61  Altura máxima do projeto licenciado (m)                           871 non-null    object\n",
      " 62  Altura máxima atual (m)                                           869 non-null    object\n",
      " 63  Comprimento da crista do projeto (m)                              869 non-null    object\n",
      " 64  Comprimento atual da crista (m)                                   869 non-null    object\n",
      " 65  Descarga máxima do vertedouro (m³/seg)                            869 non-null    object\n",
      " 66  Área do reservatório (m²)                                         869 non-null    object\n",
      " 67  Tipo de barragem quanto ao material de construção                 869 non-null    object\n",
      " 68  Tipo de fundação                                                  869 non-null    object\n",
      " 69  Vazão de projeto                                                  869 non-null    object\n",
      " 70  Método construtivo da barragem                                    869 non-null    object\n",
      " 71  Tipo de alteamento                                                869 non-null    object\n",
      " 72  Tipo de auscultação                                               869 non-null    object\n",
      " 73  A Barragem de Mineração possui Manta Impermeabilizante            869 non-null    object\n",
      " 74  Data da última Vistoria de Inspeção Regular                       904 non-null    object\n",
      " 75  Confiabilidade das estruturas extravasora                         906 non-null    object\n",
      " 76  Percolação                                                        906 non-null    object\n",
      " 77  Deformações e recalque                                            906 non-null    object\n",
      " 78  Deteriorização dos taludes / paramentos                           906 non-null    object\n",
      " 79  Documentação de projeto                                           906 non-null    object\n",
      " 80  Profissionais na equipe de Segurança da Barragem                  906 non-null    object\n",
      " 81  Manuais para Inspeções de Segurança e Monitoramento               906 non-null    object\n",
      " 82  PAE - Plano de Ação Emergencial                                   906 non-null    object\n",
      " 83  Cópias físicas do PAEBM entregues as Prefeituras e Defesas Civis  906 non-null    object\n",
      " 84  Relatórios da instrumentação e de Análise de Segurança            906 non-null    object\n",
      " 85  Volume de projeto licenciado do Reservatório (m³)                 870 non-null    object\n",
      " 86  Volume atual do Reservatório (m³)                                 868 non-null    object\n",
      " 87  Existência de população a jusante                                 868 non-null    object\n",
      " 88  N pessoas afetadas a jusante em caso de rompimento da barragem    868 non-null    object\n",
      " 89  Impacto ambiental                                                 866 non-null    object\n",
      " 90  Impacto sócio-econômico                                           866 non-null    object\n",
      " 91  Data da Finalização da DCE                                        902 non-null    object\n",
      " 92  Motivo de Envio                                                   904 non-null    object\n",
      " 93  RT/Declaração                                                     903 non-null    object\n",
      " 94  RT/Empreendimento                                                 903 non-null    object\n",
      "dtypes: int32(3), int64(1), object(91)\n",
      "memory usage: 661.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Analisando dados\n",
    "dfp_barragens.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                          int64\n",
      "ID                             int32\n",
      "Nome                          object\n",
      "Empreendedor                  object\n",
      "CPF_CNPJ                      object\n",
      "                               ...  \n",
      "Impacto sócio-econômico       object\n",
      "Data da Finalização da DCE    object\n",
      "Motivo de Envio               object\n",
      "RT/Declaração                 object\n",
      "RT/Empreendimento             object\n",
      "Length: 95, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dfp_barragens.isna().sum()\n",
    "print(dfp_barragens.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Verificando a coluna N pessoas afetadas a jusante em caso de rompimento da barragem: \n",
      "                                 Corrigir: \n",
      "0                                     1-100\n",
      "1                                         -\n",
      "2                                    875,00\n",
      "3                                  1.100,00\n",
      "4                                  1.125,00\n",
      "..                                      ...\n",
      "163                              729.000,00\n",
      "164                            5.648.000,00\n",
      "165                          154.000.000,00\n",
      "166                           12.200.000,00\n",
      "167  Projeto executivo ou \"como construído\"\n",
      "\n",
      "[168 rows x 1 columns]\n",
      "Verificação da coluna N pessoas afetadas a jusante em caso de rompimento da barragem concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Empreendedor: \n",
      "['MOSAIC FERTILIZANTES P&K LTDA.' 'MINERACAO SAO FRANCISCO DE ASSIS LTDA'\n",
      " 'MAGNESITA MINERACAO S.A. Filial: MAGNESITA MINERACAO S.A'\n",
      " 'EXTRATIVA MINERAL S/A' 'Cimento Tupi S.a.' 'VALE S.A. Filial: VALE S.A.'\n",
      " 'Ecb Rochas Ornamentais do Brasil Ltda' 'MINERACAO MATHEUS LEME LTDA'\n",
      " 'PEDREIRAS BAHIA LTDA' 'VALE S.A.' 'MAGNESITA MINERACAO S.A.'\n",
      " 'Pedreira Engebrita Ltda' 'José Vicente Nunes Rondon'\n",
      " 'COMPANHIA BAIANA DE PESQUISA MINERAL CBPM'\n",
      " 'Indústria Carbonífera Rio Deserto Ltda'\n",
      " 'Alain Stephane Riviere Mineração' 'Sidnei Rafael de Souza'\n",
      " 'João Gimenes Rodrigues' 'Frederico Augusto de Arruda Gimenez Me'\n",
      " 'Jonas Gimenez Rodrigues'\n",
      " 'Lafargeholcim (brasil) S.a. Filial: LAFARGEHOLCIM (BRASIL) S.A.'\n",
      " 'NORAIR NELSON DE SOUZA' 'Tbk Mineração Limitada'\n",
      " 'HERCULANO MINERACAO LTDA' 'MINERACAO USIMINAS S.A.'\n",
      " 'MINERACAO GERAL DO BRASIL S/A' 'MINERADORA PEDRIX LTDA'\n",
      " 'EXTRAÇAO E COMERCIO DE AREIA QUEVEDO & SILVA LTDA'\n",
      " 'Extração de Areia Taboao Ltda' 'D & L Mineração Ltda.'\n",
      " 'Mineracao Rio do Norte S A' 'CSN MINERACAO S.A.'\n",
      " 'MINERACAO RODEIO DE BAIXO LTDA Filial: MINERACAO RODEIO DE BAIXO LTDA'\n",
      " 'Pedras Congonhas Extração Arte e Ind. Ltda' 'Adão Afonso Roduí'\n",
      " 'Novelis do Brasil Ltda' 'CONCRESAND MINERACAO LTDA'\n",
      " 'Mineração Pedra Menina Ltda' 'Marcelo Bozetti'\n",
      " 'Piteiras Mineração Ltda.' 'COMPANHIA MINERADORA DO PIROCLORO DE ARAXA'\n",
      " 'Cadam S.a.' 'Mineração Taboca S.a.'\n",
      " 'Minerais & Metais Comércio e Indústria Ltda Filial: MINERAIS & METAIS COMERCIO E INDUSTRIA LTDA'\n",
      " 'EMPRESA DE MINERACAO HORII LTDA'\n",
      " 'Companhia Brasileira de Bentonita Ltda'\n",
      " 'Itaquareia Ind. Extr. Minérios Ltda' 'ATLANTIC NICKEL MINERACAO LTDA'\n",
      " 'Mineração Santa Luzia de Aguaí Ltda'\n",
      " 'EMPRESA DE MINERACAO ESPERANCA S A' 'MINERADORA PONTE ALTA LTDA'\n",
      " 'XILOLITE S/A' 'Marcir Norberto Weber' 'Realmix Agregados Minerais Ltda'\n",
      " 'TECH ROCK MINERACAO LTDA'\n",
      " 'ROZEN MINERADORA, CONSULTORIA E ASSESSORIA EM GESTAO EMPRESARIAL LTDA'\n",
      " 'COOPERATIVA MINERADORA DOS GARIMPEIROS DE ARIQUEMES - COOMIGA'\n",
      " 'Safm Mineração Ltda' 'NEXA RECURSOS MINERAIS S A'\n",
      " 'Vantage Brasil Mineração Ltda.' 'ROSEMEIRE BENEDETTI ALVES'\n",
      " 'MINERACOES GERAIS LTDA' 'Extração de Areia e Pedregulho Cachoeira Ltda.'\n",
      " 'MINERACAO CARAIBA S/A' 'Uilson Romanha & Cia Ltda'\n",
      " 'Mineração Sanguinete Ltda' 'Darci Nascimento Epp'\n",
      " 'Minerita Minérios Itaúna Ltda.' 'Evaldino Rodui'\n",
      " 'Disk Base Extração de Areia e Comercio de Materiais Para Construção Ltda Me'\n",
      " 'A R WEBER' 'ARCELORMITTAL BRASIL S.A.'\n",
      " 'ANGLO AMERICAN MINERIO DE FERRO BRASIL S/A' 'MINERACAO COMISA LTDA'\n",
      " 'MSM Mineração Serra da Moeda Ltda.' 'Mineração Vila Nova Ltda'\n",
      " 'PLINIO ALMEIDA BOSON & CIA LTDA' 'Angelo Carlos Vicari Junior'\n",
      " 'Marcelo Busnardo EPP' 'MONTE SINAI MINERACAO LTDA' 'ORO AMAPA MINERACAO'\n",
      " 'Cooperativa de Extração de Carvão Mineral dos Trabalhadores de Criciúma'\n",
      " 'GERDAU ACOMINAS S/A' 'PEDREIRA SARGON LTDA'\n",
      " 'Unidos Extração e Comércio de Areia e Pedra Ltda Epp'\n",
      " 'Norte Sul TerraplenagemComercio EIRELIMe'\n",
      " 'Mineração Nova Petrópolis Ltda.' 'QUARTZITI MINERADORA LTDA'\n",
      " 'Farias e Rodrigues Ltda Me'\n",
      " 'WHITE SOLDER METALURGIA E MINERAÇÃO LTDA Filial: WHITE SOLDER METALURGIA E MINERACAO LTDA'\n",
      " 'PORTO COMERCIO DE AREIA LTDA' 'Empresa de Mineração e Pesquisa do Amapá'\n",
      " 'CIA DE FERRO LIGAS DA BAHIA FERBASA' 'Ferro + Mineração S.A.'\n",
      " 'Mineração Jundu Ltda.' 'MULLER & CIA LTDA'\n",
      " 'METALMIG MINERACAO INDUSTRIA E COMERCIO S/A' 'VETRIA MINERACAO S.A.'\n",
      " 'BRASIL MINERIOS S/A' 'Empresa Mineradora Boa Sorte Ltda'\n",
      " 'EXTRAÇÃO E COMÉRCIO DE AREIA BOFETE LTDA' 'L Pavan & Cia Ltda'\n",
      " 'Pecuária Serramar EIRELI' 'Empresa de Mineração Fiori do Taboão Ltda.'\n",
      " 'Mineradora Areia Nova Ltda'\n",
      " 'Cbe Companhia Brasileira de Equipamento Filial: CBE COMPANHIA BRASILEIRA DE EQUIPAMENTO'\n",
      " 'Conterpa, Conservação e Terraplagem e Pavimentação Ltda'\n",
      " 'DUTRA EXTRACAO DE AREIA LTDA' 'MILTON JOSE APARECIDO GIULI'\n",
      " 'MINERACAO DIBASE PEDREIRA LTDA' 'Valdinei Mauro de Souza'\n",
      " 'SAMARCO MINERACAO S A' 'Mineral do Brasil Ltda.'\n",
      " 'Construtora Martins Lanna Ltda.'\n",
      " 'Saint Gobain do Brasil Produtos Industriais e Para Construção Ltda.'\n",
      " 'AVG EMPREENDIMENTOS MINERARIOS S.A.' 'FERROMINAS - MINERAÇÃO LTDA'\n",
      " 'PEDREIRA UM VALEMIX LTDA' 'Mib Mineração Ibirité Ltda'\n",
      " 'Alcoa World Alumina Brasil Ltda.' 'MINERACAO MORRO DO IPE S.A.'\n",
      " 'Roberto Eustáquio Silva Pedrosa' 'Massa Falida de Mundo Mineração Ltda.'\n",
      " 'Mineração Tereza Botas Ltda.'\n",
      " 'Serra Pelada Companhia de Desenvolvimento Mineral'\n",
      " 'Zamapá Mineração S.a.' 'DEV MINERACAO S.A. - EM RECUPERACAO JUDICIAL'\n",
      " 'AVB MINERACAO LTDA.' 'Mineração Descalvado Ltda'\n",
      " 'Mineração Corumbaense Reunida Sa'\n",
      " 'NIKI MINERACAO, COMERCIO E EXPORTACAO LTDA.' 'Sérgio de França'\n",
      " 'Airton Luiz Carus' 'Geominas Minerações Ltda.' 'Mineração Marsil Ltda.'\n",
      " 'Mineração Santa Luzia Limitada' 'Leonardo Pittella'\n",
      " 'MINERACAO BOM RETIRO II EIRELI' 'Manoel Rodrigues Gimenes'\n",
      " 'MINERAÇÃO BOM RETIRO LTDA.' 'VM Mineração e Construção Eireli EPP'\n",
      " 'SERGIO DA SILVA' 'FILADELFO DOS REIS DIAS' 'T G de Souza'\n",
      " 'ALTA FLORESTA GOLD MINERAÇÃO LTDA' 'Carbonífera Siderópolis Ltda.'\n",
      " 'PEDRO CERQUEIRA CALDAS' 'Yan Bittencourt nascimento'\n",
      " 'Valdemir Carlos de Souza' 'RIDALECIO DE SOUZA'\n",
      " 'Brase Brasil Extração Comercio e Industria de Estanho Ltda'\n",
      " 'SALINAS GOLD MINERACAO LTDA' 'NORMA ARGES OLIVA'\n",
      " 'COOPERATIVA DE MINERADORES E GARIMPEIROS DA REGIA'\n",
      " 'Waldomiro Chmieleski Neto' 'ITAMINAS COMERCIO DE MINERIOS SA'\n",
      " 'Ilmar Silva e Souza' 'Torio Brasil Mineração Ltda'\n",
      " 'Cooperativa de Produtores de Estanho do Brasil'\n",
      " 'COOPERATIVA DE MINERACAO DOS GARIMPEIROS DE PONTES E LACERDA - COMPEL'\n",
      " 'GDMBRASIL - GEOLOGIA E DESENVOLVIMENTO MINERAL LTDA'\n",
      " 'João Gabriel Guizzo'\n",
      " 'COOPERATIVA DE EXTRACAO DE METAIS E PEDRAS PRECIOSAS DE PONTES E LACERDA-MT'\n",
      " 'Robinson da Silva Bravo' 'Joaquim Aderaldo de Souza Neto'\n",
      " 'Mineração Maracá Industria e Comercio Sa' 'IMERYS RIO CAPIM CAULIM S.A.'\n",
      " 'VYACHESLAV RYSIN'\n",
      " 'COOPERATIVA DE EXTRACAO MINERAL DE NOSSA SENHORA DO LIVRAMENTO'\n",
      " 'CELESTA MINERACAO S.A' 'Marcelo Massaru Takahashi' 'VALE GOLD S.A.'\n",
      " 'L V R COMERCIO E EXTRACAO MINERAL LTDA' 'BURITIRAMA MINERACAO S.A.'\n",
      " 'Ronny Morais Costa' 'Minar Mineração Aredes Ltda.'\n",
      " 'Mbl Materiais Básicos Ltda' 'Granha Ligas Ltda'\n",
      " 'Bauminas Mineração Ltda' 'Humberto Covezzi'\n",
      " 'NAGELLA CHRISSIE FIRMINO BRAVO' 'Marcus Vítor Nunes Lindote'\n",
      " 'NX GOLD S.A. Filial: NX GOLD SA'\n",
      " 'GICS Indústria Comércio e Serviços S.a.'\n",
      " 'GICS Indústria Comércio e Serviços S.a. Filial: Roberto Eustáquio Silva Pedrosa'\n",
      " 'ADELSON JOSE GARCIA DA SILVA' 'Elisa Maciel Santos'\n",
      " 'Lysander Lima de França' 'EVANDRO DE SOUZA' 'Gonçalo Pedroso de Barros'\n",
      " 'Companhia Siderúrgica Nacional' 'Roberto Nunes Rondon'\n",
      " 'Companhia Brasileira do Cobre' 'Antônio da Cunha Barbosa Filho'\n",
      " 'MINERACAO SERRA GRANDE S A' 'JACOBINA MINERACAO E COMERCIO LTDA'\n",
      " 'Mara Daisy Gil Dias' 'MINERACAO TABIPORA LTDA'\n",
      " 'João de Pinho Novo Filho' 'MINERACAO DARCY R.O. E SILVA LTDA'\n",
      " 'AMG BRASIL S.A.' 'ANGLOGOLD ASHANTI CORREGO DO SITIO MINERACAO S.A.'\n",
      " 'M. M. GOLD MINERACAO LTDA' 'KINROSS BRASIL MINERACAO S/A'\n",
      " 'SAMACA FERROS LTDA' 'FAZENDA BRASILEIRO DESENVOLVIMENTO MINERAL LTDA'\n",
      " 'MINERACAO CASA DE PEDRA LTDA' 'Euler Oliveira Coelho'\n",
      " 'Ulisses José Dorileo' 'JOAO ROBERTO CARDOSO' 'Marcio Nascimento'\n",
      " 'Mineração Paragominas S A Filial: Mineração Paragominas S.A.'\n",
      " 'Copelmi Mineração Ltda' 'Mineração Paragominas S.A.'\n",
      " 'Brasmic Mineração Areia e Brita Ltda'\n",
      " 'M & J MINERACAO, PISCICULTURA E REFLORESTAMENTO - EIRELI'\n",
      " 'MINA TUCANO LTDA.' 'COMPANHIA BRASILEIRA DE ALUMINIO'\n",
      " 'Empresa de Mineração e Artefatos de Cimento Jbs Ltda Epp'\n",
      " 'MINERAÇÃO OURO BRANCO SALTO DE PIRAPORA LTDA ME' 'Mineração Apoena S A'\n",
      " 'SANTA LUZ DESENVOLVIMENTO MINERAL LTDA' 'NACIONAL DE GRAFITE LTDA'\n",
      " 'PILAR DE GOIAS DESENVOLVIMENTO MINERAL LTDA'\n",
      " 'MINERACAO RIACHO DOS MACHADOS LTDA.' 'Jeová Barbosa de Morais'\n",
      " 'Vanádio de Maracás SA'\n",
      " 'CMOC BRASIL MINERACAO, INDUSTRIA E PARTICIPACOES LTDA.'\n",
      " 'Salobo Metais Sa.' 'Reginaldo Luiz de Almeida Ferreira Me'\n",
      " 'Geocal Mineração Ltda' 'Territorial São Paulo Mineração Ltda'\n",
      " 'CARBONIFERA METROPOLITANA S/A' 'PARA PIGMENTOS S A'\n",
      " 'Mineração Serras do Oeste Eireli'\n",
      " 'Itafos Arraias Mineração e Fertilizantes S.a.' 'MINERIOS NACIONAL S.A.'\n",
      " 'COOPERATIVA DE EXTRAÇÃO MINERAL DE MATO GROSSO'\n",
      " 'JOSE MARIA OTAVIO MARTINS DUARTE' 'MINERACAO DO VALE LTDA'\n",
      " 'EMBU S A ENGENHARIA E COMERCIO'\n",
      " 'COOPERATIVA DOS GARIMPEIROS DE SANTA CRUZ - COOPERSANTA'\n",
      " 'NBF MINERACAO S.A.' 'HELLEN ELIZABETH CORREA MARTINS'\n",
      " 'VERMELHAO MINERACAO INDUSTRIA E COMERCIO LTDA'\n",
      " 'EUROMAQUINAS MINERACAO LTDA' 'Unamgen Mineração e Metalurgia S.a.'\n",
      " 'Gabriella Mineração Ltda' 'Davi Alves Bicalho' 'MINERACAO AURIZONA S/A'\n",
      " 'Isa Maria Dorileo Ferreira de Assis'\n",
      " 'Mineração Nossa Senhora do Carmo Ltda' 'SERABI MINERACAO S.A.'\n",
      " 'Mineração Vale Verde do Brasil Ltda' 'ESTANHO DE RONDONIA S/A'\n",
      " 'PROMETALICA MINERACAO EIRELI' 'VALLOUREC TUBOS DO BRASIL LTDA.'\n",
      " 'Carbonífera Belluno Ltda.' 'EMICON MINERACAO E TERRAPLENAGEM LIMITADA'\n",
      " 'MARCOS JOSE MARTINS FERNANDES' 'Extrativa Metalurgia S A'\n",
      " 'Topazio Imperial Mineração Comercio e Industria Ltda'\n",
      " 'Diego Sérgio de oliveira Almeida'\n",
      " 'Cooperativa de Mineração dos Garimpeiros do Lourenço Ltda'\n",
      " 'Cia Mineradora Catite Duo S. A.'\n",
      " 'PARÁ ALTA FLORESTA GOLD MINERAÇÃO LTDA EPP'\n",
      " 'COOPERATIVA DOS GARIMPEIROS DO VALE DO VILA NOVA' 'GINEZ GIMENES NETO'\n",
      " 'Companhia Riograndense de Mineração' 'Ricardo Padilla de Bordon Neves'\n",
      " 'RIVER GOLD MINERACAO LTDA' 'EDMAR GUERMAND DE QUEIROZ'\n",
      " 'SERRINHA GOLDMINE LTDA' 'RENALDO RUDI SCHORK' 'Gustavo Ferreira Correia'\n",
      " 'Diego Macedo Cardoso']\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna UF: \n",
      "['SE' 'PA' 'BA' 'MG' 'PI' 'SP' 'MT' 'SC' 'RS' 'AP' 'AM' 'RO' 'PB' 'RJ'\n",
      " 'TO' 'GO' 'MS' 'MA' 'PR' 'AL']\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Município: \n",
      "['ROSÁRIO DO CATETE' 'SÃO FÉLIX DO XINGU' 'SANTALUZ' 'NOVA LIMA'\n",
      " 'CARANAÍBA' 'OURILÂNDIA DO NORTE' 'CASTELO DO PIAUÍ' 'MATEUS LEME'\n",
      " 'SIMÕES FILHO' 'OURO PRETO' 'ITABIRITO' 'UBERABA' 'BRUMADO' 'SANTOS'\n",
      " 'ITABIRA' 'BARÃO DE COCAIS' 'POCONÉ' 'IRECÊ' 'MARIANA' 'IÇARA'\n",
      " 'CANAÃ DOS CARAJÁS' 'PRADOS' 'MONTE MOR' 'ITATIAIUÇU' 'BRUMADINHO'\n",
      " 'CAIEIRAS' 'TATUÍ' 'MOGI DAS CRUZES' 'VIAMÃO' 'ORIXIMINÁ' 'CONGONHAS'\n",
      " 'DESCOBERTO' 'BOFETE' 'SENADOR MODESTINO GONÇALVES' 'ARAXÁ'\n",
      " 'VITÓRIA DO JARI' 'PRESIDENTE FIGUEIREDO' 'ALMEIRIM' 'RIO CRESPO'\n",
      " 'VITÓRIA DA CONQUISTA' 'ITAGIBÁ' 'AGUAÍ' 'ROSÁRIO OESTE' 'SOROCABA'\n",
      " 'VÁRZEA' 'CAMPO NOVO DE RONDÔNIA' 'CUJUBIM' 'JARU' 'MINISTRO ANDREAZZA'\n",
      " 'URUPÁ' 'VAZANTE' 'JUÍNA' 'INHAÚMA' 'JAGUARARI' 'ITAPETININGA'\n",
      " 'SALTO DE PIRAPORA' 'DIAMANTINA' 'GUARAREMA' 'ALAMBARI'\n",
      " 'NOSSA SENHORA DO LIVRAMENTO' 'SÃO JOÃO DA BARRA' 'MAZAGÃO'\n",
      " 'SÃO LOURENÇO DO PIAUÍ' 'NOVA SANTA HELENA' 'MONTE DO CARMO' 'CALÇOENE'\n",
      " 'FORQUILHINHA' 'SANTA ISABEL' 'SARAPUÍ' 'VILHENA' 'NOVA PETRÓPOLIS'\n",
      " 'CORUMBÁ DE GOIÁS' 'BELA VISTA DE MINAS' 'ANDORINHA' 'ANALÂNDIA'\n",
      " 'ITAPUÃ DO OESTE' 'CORUMBÁ' 'SÃO LUÍS DE MONTES BELOS' 'SÃO PAULO'\n",
      " 'CARAGUATATUBA' 'CAMPO FORMOSO' 'CODÓ' 'HORTOLÂNDIA' 'CAPIVARI'\n",
      " 'PEDREIRA' 'CUIABÁ' 'MÁRIO CAMPOS' 'BETIM' 'ITUTINGA' 'SABARÁ' 'ITAÚNA'\n",
      " 'CATAS ALTAS' 'JURUTI' 'PARAUAPEBAS' 'LAGAMAR' 'RIO ACIMA' 'CURIONÓPOLIS'\n",
      " 'FERREIRA GOMES' 'PEDRA BRANCA DO AMAPARI' 'DESCALVADO' 'SANTA BÁRBARA'\n",
      " 'ANTÔNIO DIAS' 'OUVIDOR' 'PATROCÍNIO' 'NATIVIDADE' 'ITAITUBA'\n",
      " 'SÃO GONÇALO DO RIO ABAIXO' 'IBIÚNA' 'PARACATU' 'LEME'\n",
      " \"MACHADINHO D'OESTE\" 'URUSSANGA' 'PARANAÍTA' 'ARIPUANÃ' 'SARZEDO'\n",
      " 'ARIQUEMES' 'PONTES E LACERDA' 'VILA BELA DA SANTÍSSIMA TRINDADE'\n",
      " 'ALTO HORIZONTE' 'BARCARENA' 'MARABÁ' 'SÃO TIAGO' 'MERCÊS' 'MIRAÍ'\n",
      " 'NOVA XAVANTINA' 'SERRA DO SALITRE' 'ARCOS' 'CAÇAPAVA DO SUL' 'CRIXÁS'\n",
      " 'JACOBINA' 'SANTO ANTÔNIO DO GRAMA' 'CONCEIÇÃO DO MATO DENTRO'\n",
      " 'CAMPO LARGO' 'SÃO SIMÃO' 'NAZARENO' 'RIBEIRÃO BRANCO' 'BARROCAS'\n",
      " 'CAJATI' 'PATOS DE MINAS' 'TAPIRA' 'CATALÃO' 'PARAGOMINAS' 'BUTIÁ'\n",
      " 'CACHOEIRA DO SUL' 'ALMAS' 'ITAMARATI DE MINAS' 'MATIPÓ' 'ITAPECERICA'\n",
      " 'SALTO DA DIVISA' 'PEDRA AZUL' 'PILAR DE GOIÁS' 'RIACHO DOS MACHADOS'\n",
      " 'MARACÁS' 'QUATIS' 'SANTANA DE PARNAÍBA' 'MAIQUINIQUE' 'JECEABA'\n",
      " 'RIO PIRACICABA' 'BELO VALE' 'TREVISO' 'IPIXUNA DO PARÁ' 'ARRAIAS'\n",
      " 'CORUMBATAÍ' 'NOVA LACERDA' 'SIDERÓPOLIS' 'GODOFREDO VIANA' 'CAETÉ'\n",
      " 'CERRO AZUL' 'CONCEIÇÃO DO PARÁ' 'CRAÍBAS' 'RIO BRANCO' 'LAURO MÜLLER'\n",
      " 'IGARAPÉ' 'FORTALEZA DE MINAS' 'NOVA ERA' 'JACAREACANGA' 'PORTO GRANDE'\n",
      " 'MINAS DO LEÃO' 'SÃO JOSÉ DOS QUATRO MARCOS']\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Categoria de Risco - CRI: \n",
      "['Não se aplica' 'Baixa' 'Média' 'Alta']\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Nível de Emergência: \n",
      "['Sem emergência' 'Emergência Nivel 1' 'Emergência Nivel 3'\n",
      " 'Emergência Nivel 2']\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Tipo de Barragem de Mineração: \n",
      "['Barragem/Barramento/Dique' 'Cava com Barramento Construído'\n",
      " 'Empilhamento drenado construído hidraulicamente e suscetível à liquefação']\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Vida útil prevista da Barragem (anos): \n",
      "['34,00' '-' '14,00' '10,00' '46,00' '50,00' '61,00' '93,00' '12,00'\n",
      " '20,00' '1,00' '0,00' '9,00' '42,00' '22,00' '15,00' '37,00' '5,00'\n",
      " '21,00' '18,00' '26,00' '100,00' '30,00' '19,00' '27,00' '11,00' '3,00'\n",
      " '8,00' '6,00' '47,00' '44,00' '4,00' '25,00' '2,00' '7,00' '39,00'\n",
      " '35,00' '56,00' '16,00' '13,00' '57,00' '88,00' '1,50' '33,00' '2,08'\n",
      " '48,00' '17,00' '40,00' '2,50' '55,00' '24,00' '38,00' '23,00' '999,00'\n",
      " '70,00' '52,00' '51,00' '29,00' '85,00' '32,00' '110,00' '69,00' '2,58'\n",
      " '74,00' '53,00' '89,00' '54,00' '92,00' '6,50' '71,00']\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Estrutura com o Objetivo de Contenção: \n",
      "['Rejeitos' 'Sedimentos']\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Minério principal presente no reservatório: \n",
      "['Sais' 'Areia' 'Cromita' 'Não se aplica a esse tipo de barragem'\n",
      " 'Argila Refratária' 'Argila' 'Magnesita' 'Fosfato' 'Minério de Ferro'\n",
      " 'Argila Arenosa' 'Calcário Dolomítico' 'Bauxita Grau Metalúrgico'\n",
      " 'Minério de Manganês' 'Minério de Estanho Primário' 'Caulim'\n",
      " 'Aluvião Aurífero' 'Areia Quartzosa' 'Areia e Cascalho'\n",
      " 'Rocha Diamantífera' 'Rocha Aurífera' 'Minério de Cromo' 'Saibro'\n",
      " 'Minério de Ouro Primário' 'PLANTA DE BENEFICIAMENTO'\n",
      " 'Aluvião Estanífero' 'Vermiculita' 'Usina Pedrinhas' 'Minério de Cobre'\n",
      " 'Calcário' 'Bauxita Grau Não Metalúrgico' '-' 'Itabirito'\n",
      " 'Usina Vidreira' 'Minério de Ouro Secundário' 'USINA SÃO GONÇALO'\n",
      " 'Aluvião Diamantífero' 'Hematita' 'Rocha Fosfática' 'Arenito'\n",
      " 'Argila Caulinítica' 'Pegmatito' 'ROBERT BUCHAN' 'Silvanita'\n",
      " 'Carvão Mineral' 'Xisto' 'ITM VGR02' 'Minério de Vanádio' 'ITM D'\n",
      " 'Minério de Níquel' 'REJEITO' 'Minério de Nióbio'\n",
      " 'Carvão Mineral Camada Bonito' 'Usina Chapadão' 'PLANTA BOM FUTURO'\n",
      " 'Granito' 'Usina Conceição I e Usina Conceição II)'\n",
      " 'Minério de Estanho Secundário' 'Carvão Mineral Camada Barro Branco'\n",
      " 'Planta de Beneficiamento 02' 'Fluorita' 'Minério de Zinco'\n",
      " 'Planta de Processamento ACR'\n",
      " 'USINA DE BRITAGEM E CLASSIFICAÇÃO - PEDREIRA JURUAÇU' 'UTM - Ipê'\n",
      " 'Aluvião com Gemas' 'Unidade de Vazante - Zinco'\n",
      " 'Usina Morro Agudo Zn e Pb']\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna N pessoas afetadas a jusante em caso de rompimento da barragem: \n",
      "['1-100' '-' '875,00' '1.100,00' '1.125,00'\n",
      " 'Inexistente (Não existem pessoas permanentes/residentes ou temporárias/transitando na área afetada a jusante da barragem)'\n",
      " '7.300,00' '4.300,00' '4.600,00'\n",
      " 'Pouco Frequente (Não existem pessoas ocupando permanentemente a área afetada a jusante da barragem, mas existe estrada vicinal de uso local)'\n",
      " '7.100,00' '4.900,00' '3.900,00' '57.000,00' '8.000,00' '36.000,00'\n",
      " '5.000,00' '600.000,00' '2,00' '3.000,00' '424.000,00' '90,00' '3.420,00'\n",
      " '4.078,00' '650.000,00' '700.000,00' '7.500,00' '100,00' '39.000,00'\n",
      " '45.500,00' '80.000,00' '185.520,00' '0,00' '94.325,00' '10.275,00'\n",
      " '7.557,00' '5.397,71' '4.385,00' '3.766,00' '2.319,80' '7.259,80'\n",
      " '5.233,20' '385.000,00' '29.688,00'\n",
      " 'Não se aplica a esse tipo de barragem' '7.546.484,00' '2.551.310,00'\n",
      " '750.000,00' None\n",
      " 'Não emite regularmente relatórios de inspeção e monitoramento e de Análise de Segurança'\n",
      " '192.200,00' '92.000,00' '76.000,00' '324.121,27' '200.000,00' '9.064,00'\n",
      " '1.500.000,00' '24.000,00'\n",
      " 'Frequente (Não existem pessoas ocupando permanentemente a área afetada a jusante da barragem, mas existe rodovia municipal ou estadual ou federal ou outro local e/ou empreendimento de permanência eventual de pessoas que poderão ser atingidas)'\n",
      " '2.100.000,00' '65.458,90' '64.000,00' '4.500.000,00' '500.000,00'\n",
      " '4.000.000,00'\n",
      " 'Emite regularmente relatórios de inspeção e monitoramento com base na instrumentação e de Análise de Segurança'\n",
      " 'Existente (Existem pessoas ocupando permanentemente a área afetada a jusante da barragem, portanto, vidas humanas poderão ser atingidas)'\n",
      " '2.000,00' '237.000,00' '1.450.000,00'\n",
      " 'Emite regularmente APENAS relatórios de inspeção e monitoramento'\n",
      " '124.000,00' '1.890.000,00'\n",
      " 'Possui unidade administrativa com profissional técnico qualificado responsável pela segurança da barragem'\n",
      " '282.779,28' 'Projeto básico'\n",
      " 'Possui manuais de procedimentos para inspeção, monitoramento e operação'\n",
      " '101-500' '658.400,00' '1.258.400,00' '584,00'\n",
      " 'Projeto executivo e \"como construído\"'\n",
      " '0 - Percolação totalmente controlada pelo sistema de drenagem'\n",
      " '1001-5000' '750.000.000,00' 'Sim' '483.000.000,00' '260.000,00'\n",
      " '13.770.423,00' '1.721.104,00' '2.383.500,00' '721.970,36' '8.708.062,00'\n",
      " '169.670.660,16' '80.000.000,00'\n",
      " 'Não possui PAE (não é exigido pelo órgão fiscalizador)' '25.450.713,00'\n",
      " '6.377.283,00' '1.540.000,00' '15.029.999,01' '65.875,80' '18.637.900,00'\n",
      " '2.813.137,96' '55.000,00' '800.000,00' '4.800.000,00' '156.260,00'\n",
      " '17.500.000,00'\n",
      " '0 - Estruturas civis bem mantidas e em operação normal / barragem sem necessidade de estruturas extravasoras'\n",
      " 'Possui PAE' '7.177.241,71' '501-1000'\n",
      " 'CMP (Cheia Máxima Provável) ou Decamilenar' '625.000,00' '12.763.176,54'\n",
      " '22.778.397,90' '19.476.113,00' '4.460.000,00' '2.790.000,00'\n",
      " '2.310.000,00' '4.820.000,00' '3.420.000,00' '2.480.000,00'\n",
      " 'acima de 5001' '34.000.000,00' '10.924.076,00' '2.685.782,00'\n",
      " 'Possui profissional técnico qualificado (próprio ou contratado) responsável pela segurança da barragem'\n",
      " '7.723.600,00' '1.724.296,94' '68.500,00' '639.854,00' '1.480.555,00'\n",
      " '502.671,00' '8.032,89' '1.100.000,00' '2.920.000,00' '103.000,00'\n",
      " '2.632.000,00' '1.183.119,15' '23.500.000,00' '375.000,00' '154.433,29'\n",
      " '3.748.232,99' '4.455.613,00' '3.595.017,00' '3.717.626,00'\n",
      " '9.170.673,00' 'Não' '440.300,00' '29.800,00'\n",
      " '0 - Não existem deformações e recalques com potencial de comprometimento da segurança da estrutura'\n",
      " '115.239,00' '150.000,00' '6.893.674,00' '2.506.251,00' '1.763.201,25'\n",
      " '1.547.945,70' '1.461.978,61' '3.900.000,00' '571.815,00' '2.200,00'\n",
      " '657.575,00' '729.000,00' '5.648.000,00' '154.000.000,00' '12.200.000,00'\n",
      " 'Projeto executivo ou \"como construído\"']\n",
      "Verificação concluída\n"
     ]
    }
   ],
   "source": [
    "verificacao_tipo(dfp_barragens, 'N pessoas afetadas a jusante em caso de rompimento da barragem', float)\n",
    "verificacao_valor_padrao(dfp_barragens, 'Empreendedor')\n",
    "verificacao_valor_padrao(dfp_barragens, 'UF')\n",
    "verificacao_valor_padrao(dfp_barragens, 'Município')\n",
    "verificacao_valor_padrao(dfp_barragens, 'Categoria de Risco - CRI')\n",
    "verificacao_valor_padrao(dfp_barragens, 'Nível de Emergência')\n",
    "verificacao_valor_padrao(dfp_barragens, 'Tipo de Barragem de Mineração')\n",
    "verificacao_valor_padrao(dfp_barragens, 'Vida útil prevista da Barragem (anos)')\n",
    "verificacao_valor_padrao(dfp_barragens, 'Estrutura com o Objetivo de Contenção')\n",
    "verificacao_valor_padrao(dfp_barragens, 'Minério principal presente no reservatório')\n",
    "verificacao_valor_padrao(dfp_barragens, 'N pessoas afetadas a jusante em caso de rompimento da barragem')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando inconsistencias no dataframe dados_populacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando DataFrame Dados População Spark em DataFrame Pandas\n",
    "dfp_dados_populacao = dfs_dados_populacao.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                                              int64\n",
      "Ano                                                int64\n",
      "Esperança de Vida ao Nascer                      float64\n",
      "Esperança de Vida ao Nascer - Homens             float64\n",
      "Esperança de Vida ao Nascer - Mulheres           float64\n",
      "Homens                                             int64\n",
      "Mulheres                                           int64\n",
      "Nascimentos                                        int64\n",
      "População total                                    int64\n",
      "Razão de Dependência                             float64\n",
      "Razão de Dependência - Idosos 65 ou mais anos    float64\n",
      "Razão de Dependência - Jovens 0 a 14 anos        float64\n",
      "Taxa Bruta de Mortalidade                        float64\n",
      "Taxa Bruta de Natalidade                         float64\n",
      "Taxa de Crescimento Geométrico                    object\n",
      "Taxa de Fecundidade Total                        float64\n",
      "Taxa de Mortalidade Infantil                     float64\n",
      "Taxa de Mortalidade Infantil - Homens            float64\n",
      "Taxa de Mortalidade Infantil - Mulheres          float64\n",
      "uf                                                object\n",
      "Índice de Envelhecimento                         float64\n",
      "Óbitos                                             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Analisando dados\n",
    "print(dfp_dados_populacao.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Ano</th>\n",
       "      <th>Esperança de Vida ao Nascer</th>\n",
       "      <th>Esperança de Vida ao Nascer - Homens</th>\n",
       "      <th>Esperança de Vida ao Nascer - Mulheres</th>\n",
       "      <th>Homens</th>\n",
       "      <th>Mulheres</th>\n",
       "      <th>Nascimentos</th>\n",
       "      <th>População total</th>\n",
       "      <th>Razão de Dependência</th>\n",
       "      <th>...</th>\n",
       "      <th>Taxa Bruta de Mortalidade</th>\n",
       "      <th>Taxa Bruta de Natalidade</th>\n",
       "      <th>Taxa de Crescimento Geométrico</th>\n",
       "      <th>Taxa de Fecundidade Total</th>\n",
       "      <th>Taxa de Mortalidade Infantil</th>\n",
       "      <th>Taxa de Mortalidade Infantil - Homens</th>\n",
       "      <th>Taxa de Mortalidade Infantil - Mulheres</th>\n",
       "      <th>uf</th>\n",
       "      <th>Índice de Envelhecimento</th>\n",
       "      <th>Óbitos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>71.68</td>\n",
       "      <td>68.46</td>\n",
       "      <td>75.4</td>\n",
       "      <td>384406</td>\n",
       "      <td>380919</td>\n",
       "      <td>16489</td>\n",
       "      <td>765325</td>\n",
       "      <td>66.22</td>\n",
       "      <td>...</td>\n",
       "      <td>5.09</td>\n",
       "      <td>21.55</td>\n",
       "      <td>x</td>\n",
       "      <td>2.45</td>\n",
       "      <td>22.08</td>\n",
       "      <td>24.17</td>\n",
       "      <td>19.88</td>\n",
       "      <td>AC</td>\n",
       "      <td>11.8</td>\n",
       "      <td>3899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   Ano  Esperança de Vida ao Nascer  \\\n",
       "0      0  2010                        71.68   \n",
       "\n",
       "   Esperança de Vida ao Nascer - Homens  \\\n",
       "0                                 68.46   \n",
       "\n",
       "   Esperança de Vida ao Nascer - Mulheres  Homens  Mulheres  Nascimentos  \\\n",
       "0                                    75.4  384406    380919        16489   \n",
       "\n",
       "   População total  Razão de Dependência  ...  Taxa Bruta de Mortalidade  \\\n",
       "0           765325                 66.22  ...                       5.09   \n",
       "\n",
       "   Taxa Bruta de Natalidade  Taxa de Crescimento Geométrico  \\\n",
       "0                     21.55                               x   \n",
       "\n",
       "   Taxa de Fecundidade Total Taxa de Mortalidade Infantil  \\\n",
       "0                       2.45                        22.08   \n",
       "\n",
       "   Taxa de Mortalidade Infantil - Homens  \\\n",
       "0                                  24.17   \n",
       "\n",
       "   Taxa de Mortalidade Infantil - Mulheres  uf  Índice de Envelhecimento  \\\n",
       "0                                    19.88  AC                      11.8   \n",
       "\n",
       "  Óbitos  \n",
       "0   3899  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_dados_populacao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Ano: \n",
      "[2010]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Esperança de Vida ao Nascer: \n",
      "[71.68]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Esperança de Vida ao Nascer - Homens: \n",
      "[68.46]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Esperança de Vida ao Nascer - Mulheres: \n",
      "[75.4]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Homens: \n",
      "[384406]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Mulheres: \n",
      "[380919]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Nascimentos: \n",
      "[16489]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna População total: \n",
      "[765325]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Razão de Dependência: \n",
      "[66.22]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Razão de Dependência - Idosos 65 ou mais anos: \n",
      "[6.97]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Razão de Dependência - Jovens 0 a 14 anos: \n",
      "[59.25]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Taxa Bruta de Mortalidade: \n",
      "[5.09]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Taxa Bruta de Natalidade: \n",
      "[21.55]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Taxa de Crescimento Geométrico: \n",
      "['x']\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Taxa de Fecundidade Total: \n",
      "[2.45]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Taxa de Mortalidade Infantil: \n",
      "[22.08]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Taxa de Mortalidade Infantil - Homens: \n",
      "[24.17]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Taxa de Mortalidade Infantil - Mulheres: \n",
      "[19.88]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Índice de Envelhecimento: \n",
      "[11.8]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna Óbitos: \n",
      "[3899]\n",
      "Verificação concluída\n",
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna uf: \n",
      "['AC']\n",
      "Verificação concluída\n"
     ]
    }
   ],
   "source": [
    "verificacao_valor_padrao(dfp_dados_populacao, 'Ano')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Esperança de Vida ao Nascer')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Esperança de Vida ao Nascer - Homens')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Esperança de Vida ao Nascer - Mulheres')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Homens')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Mulheres')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Nascimentos')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'População total')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Razão de Dependência')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Razão de Dependência - Idosos 65 ou mais anos')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Razão de Dependência - Jovens 0 a 14 anos')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Taxa Bruta de Mortalidade')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Taxa Bruta de Natalidade')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Taxa de Crescimento Geométrico')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Taxa de Fecundidade Total')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Taxa de Mortalidade Infantil')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Taxa de Mortalidade Infantil - Homens')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Taxa de Mortalidade Infantil - Mulheres')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Índice de Envelhecimento')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'Óbitos')\n",
    "verificacao_valor_padrao(dfp_dados_populacao, 'uf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando inconsistências na DF municipio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando o dataframe municipio spark em Dataframe Pandas\n",
    "dfp_municipio = dfs_municipio.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "Verificando valores únicos da coluna UF: \n",
      "['RO' 'AC' 'AM' 'RR' 'PA' 'AP' 'TO' 'MA' 'PI' 'CE' 'RN' 'PB' 'PE' 'AL'\n",
      " 'SE' 'BA' 'MG' 'ES' 'RJ' 'SP' 'PR' 'SC' 'RS' 'MS' 'MT' 'GO' 'DF']\n",
      "Verificação concluída\n",
      "--------------------------------------------------------------------\n",
      "Verificando a coluna COD. UF: \n",
      "Nenhum problema detectado nessa coluna\n",
      "Verificação da coluna COD. UF concluída\n",
      "Nenhum problema detectado nesta coluna\n",
      "Verificação da coluna COD. UF concluída\n",
      "--------------------------------------------------------------------\n",
      "Verificando a coluna COD. MUNIC: \n",
      "Nenhum problema detectado nessa coluna\n",
      "Verificação da coluna COD. MUNIC concluída\n",
      "                  Corrigir:\n",
      "0     Alta Floresta D'Oeste\n",
      "1         Colorado do Oeste\n",
      "2             Costa Marques\n",
      "3           Espigão D'Oeste\n",
      "4             Guajará-Mirim\n",
      "...                     ...\n",
      "2536   Terezópolis de Goiás\n",
      "2537           Três Ranchos\n",
      "2538    Valparaíso de Goiás\n",
      "2539               Vila Boa\n",
      "2540          Vila Propício\n",
      "\n",
      "[2541 rows x 1 columns]\n",
      "Verificação da coluna NOME DO MUNICÍPIO concluída\n",
      "--------------------------------------------------------------------\n",
      "Verificando a coluna POPULAÇÃO ESTIMADA: \n",
      "     Corrigir: \n",
      "0    548.952(1)\n",
      "1     44.873(2)\n",
      "2     13.482(3)\n",
      "3     17.193(4)\n",
      "4     13.462(5)\n",
      "5     47.685(6)\n",
      "6     33.981(7)\n",
      "7     2.255.903\n",
      "8    116.439(8)\n",
      "9     26.566(9)\n",
      "10   68.502(10)\n",
      "11   16.007(11)\n",
      "12   24.098(12)\n",
      "13    1.506.420\n",
      "14    6.952(13)\n",
      "15  125.265(14)\n",
      "16    1.115.932\n",
      "17    2.703.391\n",
      "18   12.216(15)\n",
      "19    1.661.017\n",
      "20    1.031.597\n",
      "21   15.549(16)\n",
      "22    8.849(17)\n",
      "23    9.548(18)\n",
      "24    2.900.319\n",
      "25   44.185(19)\n",
      "26    2.530.701\n",
      "27    6.775.561\n",
      "28    1.098.357\n",
      "29    1.223.237\n",
      "30    1.404.694\n",
      "31   12.396.372\n",
      "32    1.963.726\n",
      "33    1.492.530\n",
      "34    1.555.626\n",
      "35    3.094.325\n",
      "Verificação da coluna POPULAÇÃO ESTIMADA concluída\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corrigir:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>548.952(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.873(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.482(3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.193(4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.462(5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47.685(6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33.981(7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.255.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>116.439(8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26.566(9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>68.502(10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.007(11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>24.098(12)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.506.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.952(13)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>125.265(14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.115.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.703.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12.216(15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.661.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.031.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15.549(16)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.849(17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.548(18)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.900.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>44.185(19)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.530.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.775.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.098.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.223.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.404.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12.396.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.963.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.492.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.555.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3.094.325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Corrigir: \n",
       "0    548.952(1)\n",
       "1     44.873(2)\n",
       "2     13.482(3)\n",
       "3     17.193(4)\n",
       "4     13.462(5)\n",
       "5     47.685(6)\n",
       "6     33.981(7)\n",
       "7     2.255.903\n",
       "8    116.439(8)\n",
       "9     26.566(9)\n",
       "10   68.502(10)\n",
       "11   16.007(11)\n",
       "12   24.098(12)\n",
       "13    1.506.420\n",
       "14    6.952(13)\n",
       "15  125.265(14)\n",
       "16    1.115.932\n",
       "17    2.703.391\n",
       "18   12.216(15)\n",
       "19    1.661.017\n",
       "20    1.031.597\n",
       "21   15.549(16)\n",
       "22    8.849(17)\n",
       "23    9.548(18)\n",
       "24    2.900.319\n",
       "25   44.185(19)\n",
       "26    2.530.701\n",
       "27    6.775.561\n",
       "28    1.098.357\n",
       "29    1.223.237\n",
       "30    1.404.694\n",
       "31   12.396.372\n",
       "32    1.963.726\n",
       "33    1.492.530\n",
       "34    1.555.626\n",
       "35    3.094.325"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando as colunas:\n",
    "verificacao_valor_padrao(dfp_municipio,  \"UF\")\n",
    "verificacao_tipo(dfp_municipio, \"COD. UF\", int)\n",
    "verificacao_texto(dfp_municipio, \"COD. UF\", 2, True)\n",
    "verificacao_tipo(dfp_municipio, \"COD. MUNIC\", int)\n",
    "verificacao_texto(dfp_municipio, \"NOME DO MUNICÍPIO\", None, False)\n",
    "verificacao_tipo(dfp_municipio, \"POPULAÇÃO ESTIMADA\", float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>COD. UF</th>\n",
       "      <th>COD. MUNIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5570.000000</td>\n",
       "      <td>5570.000000</td>\n",
       "      <td>5570.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2784.500000</td>\n",
       "      <td>32.377738</td>\n",
       "      <td>15816.982585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1608.064831</td>\n",
       "      <td>9.833862</td>\n",
       "      <td>15997.299780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1392.250000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>4507.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2784.500000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>10400.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4176.750000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>20853.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5569.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>72202.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index      COD. UF    COD. MUNIC\n",
       "count  5570.000000  5570.000000   5570.000000\n",
       "mean   2784.500000    32.377738  15816.982585\n",
       "std    1608.064831     9.833862  15997.299780\n",
       "min       0.000000    11.000000     13.000000\n",
       "25%    1392.250000    25.000000   4507.250000\n",
       "50%    2784.500000    31.000000  10400.500000\n",
       "75%    4176.750000    41.000000  20853.000000\n",
       "max    5569.000000    53.000000  72202.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_municipio.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_municipio.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                 0\n",
       "UF                    0\n",
       "COD. UF               0\n",
       "COD. MUNIC            0\n",
       "NOME DO MUNICÍPIO     0\n",
       "POPULAÇÃO ESTIMADA    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_municipio.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotagens Preliminares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrecadacao\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Total Arrecadado por ano\")\n",
    "plt.plot(dfp_arrecadacao[\"Ano\"], dfp_arrecadacao[\"ValorRecolhido\"])\n",
    "plt.xlabel(\"Ano\")\n",
    "plt.ylabel(\"Número de Ocorrências\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisando os dados depois de Tratados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrecadacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Puxando o o data frame tratado do bucket\n",
    "'''\n",
    "df_arrecadacao = spark.read.csv(\"gs://soulcode-mineracao/tratados/arrecadacao.csv\", sep=',', encoding='utf-8', header=True)\n",
    "df_arrecadacao = df_arrecadacao.withColumnRenamed(\"Substância\", \"Substancia\").withColumnRenamed(\"Mês\", \"Mes\").withColumnRenamed(\"Município\", \"Municipio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ano',\n",
       " 'Mes',\n",
       " 'Processo',\n",
       " 'AnoDoProcesso',\n",
       " 'Tipo_PF_PJ',\n",
       " 'Substancia',\n",
       " 'UF',\n",
       " 'Municipio',\n",
       " 'QuantidadeComercializada',\n",
       " 'UnidadeDeMedida',\n",
       " 'ValorRecolhido']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arrecadacao.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "z-GDQpY0-m-m"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Cria ou substitui uma visão temporária para o DataFrame\n",
    "\n",
    "O tempo de vida dessa tabela temporária está vinculado à \n",
    "SparkSession que foi usada para criar o DataFrame.\n",
    "\n",
    "'''\n",
    "\n",
    "df_arrecadacao.createOrReplaceTempView('arrecadacao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "-_hGe-1o_N8B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 1657294|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "> COUNT\n",
    "Contando a quantidade de linhas do Dataframe\n",
    "'''\n",
    "spark.sql('''SELECT COUNT (*)\n",
    "          FROM arrecadacao\n",
    "          ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "q44gaL-E_Qri"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| Ano|\n",
      "+----+\n",
      "|2002|\n",
      "|2003|\n",
      "|2004|\n",
      "|2005|\n",
      "|2006|\n",
      "|2007|\n",
      "|2008|\n",
      "|2009|\n",
      "|2010|\n",
      "|2011|\n",
      "|2012|\n",
      "|2013|\n",
      "|2014|\n",
      "|2015|\n",
      "|2016|\n",
      "|2017|\n",
      "|2018|\n",
      "|2019|\n",
      "|2020|\n",
      "|2021|\n",
      "|2022|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "> DISTINCT\n",
    "Consultando apenas os valores distintos\n",
    "Aplicando, como exemplo, a coluna 'Ano'.\n",
    "'''\n",
    "\n",
    "spark.sql('''SELECT DISTINCT Ano\n",
    "          FROM arrecadacao\n",
    "          ORDER BY Ano\n",
    "          ''').show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "nizP7IOj_atZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------------+\n",
      "|  UF|QuantidadeComercializada|\n",
      "+----+------------------------+\n",
      "|  GO|        9183313766101.26|\n",
      "|  MG|        8768631954947.87|\n",
      "|  SP|        6364884182577.36|\n",
      "|  PB|         720245324293.12|\n",
      "|  AP|         464456059814.76|\n",
      "|  RS|         189459061922.14|\n",
      "|  DF|         122644869084.48|\n",
      "|  RJ|         120209532126.80|\n",
      "|  MA|          93153116399.30|\n",
      "|  SC|          71489575584.17|\n",
      "|  BA|          47709341949.63|\n",
      "|  MS|          30415871547.41|\n",
      "|  PA|          24468919173.55|\n",
      "|  PR|          16775349626.24|\n",
      "|  AM|          15155884589.54|\n",
      "|  PE|          10203767508.34|\n",
      "|  RN|          10196596252.01|\n",
      "|  SE|           9416274536.25|\n",
      "|  AL|           8536400669.33|\n",
      "|  CE|           7068395217.58|\n",
      "|  TO|           6334523495.39|\n",
      "|  ES|           3103633530.43|\n",
      "|  PI|           2902046048.37|\n",
      "|  RO|           1635857770.09|\n",
      "|  RR|            331384919.76|\n",
      "|  AC|            216741034.70|\n",
      "|null|             54910567.93|\n",
      "|  MT|                    null|\n",
      "+----+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "> SOMA\n",
    "Consulta para a soma da quantidade comercializada por estado da view 'teste',\n",
    "agrupadas por estado e ordenadas do maior ao menor valor da soma da\n",
    "quantidade comercializada em ordem decrescente\n",
    "'''\n",
    "spark.sql('''SELECT UF, cast(SUM(QuantidadeComercializada) as DECIMAL(15,2)) as QuantidadeComercializada\n",
    "             FROM arrecadacao \n",
    "             GROUP BY UF\n",
    "             ORDER BY QuantidadeComercializada DESC\n",
    "             ''').show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "xgV8SaLB_cnx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------------+\n",
      "|  UF|QuantidadeComercializada|\n",
      "+----+------------------------+\n",
      "|  MT|            179977695.06|\n",
      "|  GO|            123844451.48|\n",
      "|  AP|             87139973.70|\n",
      "|  MG|             34020702.54|\n",
      "|  PB|             32344410.11|\n",
      "|  DF|             24937956.30|\n",
      "|  SP|             23575740.74|\n",
      "|  MA|              4868205.72|\n",
      "|  AM|              1597374.01|\n",
      "|  RJ|              1552573.19|\n",
      "|  RS|              1138042.64|\n",
      "|  AL|              1108335.58|\n",
      "|  MS|               867587.19|\n",
      "|  RN|               854988.79|\n",
      "|  BA|               850615.85|\n",
      "|  SE|               713030.03|\n",
      "|  TO|               510313.66|\n",
      "|  PA|               485436.64|\n",
      "|  SC|               443637.84|\n",
      "|  PE|               388922.38|\n",
      "|  CE|               215335.73|\n",
      "|  PI|               154594.40|\n",
      "|  PR|               127531.38|\n",
      "|  RR|                94304.19|\n",
      "|  AC|                81328.72|\n",
      "|  RO|                58234.23|\n",
      "|  ES|                43304.50|\n",
      "|null|                35563.84|\n",
      "+----+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "> MÉDIA\n",
    "Consulta para a média da quantidade comercializada por estado da view 'teste',\n",
    "agrupadas por estado e ordenadas do maior ao menor valor da média da\n",
    "quantidade comercializada em ordem decrescente\n",
    "'''\n",
    "\n",
    "spark.sql('''SELECT UF, cast(AVG(QuantidadeComercializada) as DECIMAL(15,2)) as QuantidadeComercializada\n",
    "             FROM arrecadacao \n",
    "             GROUP BY UF\n",
    "             ORDER BY QuantidadeComercializada DESC\n",
    "             ''').show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0E6gYXA_hjT"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "> SOMA\n",
    "Consulta para a soma do valor recolhido da view 'teste',\n",
    "agrupadas por ano e uf e ordenadas por ano e soma do\n",
    "valor recolhido em ordem decrescente\n",
    "'''\n",
    "\n",
    "spark.sql('''SELECT Ano, UF, cast(SUM(ValorRecolhido) as DECIMAL(15,2)) as ValorRecolhido\n",
    "             FROM arrecadacao \n",
    "             GROUP BY Ano, UF\n",
    "             ORDER BY Ano, ValorRecolhido DESC\n",
    "             ''').show(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTZvIDwM_l-6"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "> MÉDIA\n",
    "Consulta para a média do valor recolhido da view 'teste',\n",
    "agrupadas por ano e uf e ordenadas por ano e média do\n",
    "valor recolhido em ordem decrescente\n",
    "'''\n",
    "\n",
    "spark.sql('''SELECT Ano, UF, cast(AVG(ValorRecolhido) as DECIMAL(15,2)) as ValorRecolhido\n",
    "             FROM arrecadacao \n",
    "             GROUP BY Ano, UF\n",
    "             ORDER BY Ano, ValorRecolhido DESC\n",
    "             ''').show(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT DISTINCT unidadedemedida from arrecadacao\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Table or view not found: arrecadacao; line 1 pos 112'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o57.sql.\n: org.apache.spark.sql.AnalysisException: Table or view not found: arrecadacao; line 1 pos 112\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:47)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:798)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:750)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$6.applyOrElse(Analyzer.scala:780)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$6.applyOrElse(Analyzer.scala:773)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$3(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$1(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:84)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$2(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$1(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:84)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$2(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$1(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:84)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$2(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$1(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:84)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:773)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:719)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:87)\n\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n\tat scala.collection.immutable.List.foldLeft(List.scala:89)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:76)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:121)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:48)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:643)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.sql.catalyst.analysis.NoSuchTableException: Table or view 'arrecadacao' not found in database 'default';\n\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalog.requireTableExists(ExternalCatalog.scala:48)\n\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalog.requireTableExists$(ExternalCatalog.scala:46)\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.requireTableExists(InMemoryCatalog.scala:45)\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.getTable(InMemoryCatalog.scala:326)\n\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.getTable(ExternalCatalogWithListener.scala:138)\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.lookupRelation(SessionCatalog.scala:706)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:795)\n\t... 68 more\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e6f0d2e3ea28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m '''\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m spark.sql(\"SELECT Substancia, Cast(SUM(QUANTIDADECOMERCIALIZADA) as DECIMAL(25,3)) as SomaQuantidadeComercializada_m3 \"\n\u001b[0m\u001b[1;32m      6\u001b[0m           \"FROM arrecadacao WHERE UnidadeDeMedida = 'Metros Cubicos' GROUP BY(Substancia) ORDER BY SUM(QUANTIDADECOMERCIALIZADA) DESC\").show(10)\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \"\"\"\n\u001b[0;32m--> 767\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Table or view not found: arrecadacao; line 1 pos 112'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Consulta dos 10 minérios mais comercializados, por unidade de medida\n",
    "'''\n",
    "\n",
    "spark.sql(\"SELECT Substancia, Cast(SUM(QUANTIDADECOMERCIALIZADA) as DECIMAL(25,3)) as SomaQuantidadeComercializada_m3 \"\n",
    "          \"FROM arrecadacao WHERE UnidadeDeMedida = 'Metros Cubicos' GROUP BY(Substancia) ORDER BY SUM(QUANTIDADECOMERCIALIZADA) DESC\").show(10)\n",
    "\n",
    "spark.sql(\"SELECT Substancia, Cast(SUM(QUANTIDADECOMERCIALIZADA) as DECIMAL(25,3)) as SomaQuantidadeComercializada_m2 \"\n",
    "          \"FROM arrecadacao WHERE UnidadeDeMedida = 'Metros Quadrados' GROUP BY(Substancia) ORDER BY SUM(QUANTIDADECOMERCIALIZADA) DESC\").show(20)\n",
    "\n",
    "spark.sql(\"SELECT Substancia, Cast(SUM(QUANTIDADECOMERCIALIZADA) as DECIMAL(25,3)) as SomaQuantidadeComercializada_null \"\n",
    "          \"FROM arrecadacao WHERE UnidadeDeMedida is NULL GROUP BY(Substancia) ORDER BY SUM(QUANTIDADECOMERCIALIZADA) DESC\").show(20)\n",
    "\n",
    "spark.sql(\"SELECT Substancia, Cast(SUM(QUANTIDADECOMERCIALIZADA) as DECIMAL(25,3)) as SomaQuantidadeComercializada_T \"\n",
    "          \"FROM arrecadacao WHERE UnidadeDeMedida = 'Toneladas' GROUP BY(Substancia) ORDER BY SUM(QUANTIDADECOMERCIALIZADA) DESC\").show(10)\n",
    "\n",
    "spark.sql(\"SELECT Substancia, Cast(SUM(QUANTIDADECOMERCIALIZADA) as DECIMAL(25,3)) as SomaQuantidadeComercializada_L \"\n",
    "          \"FROM arrecadacao WHERE UnidadeDeMedida = 'Litros' GROUP BY(Substancia) ORDER BY SUM(QUANTIDADECOMERCIALIZADA) DESC\").show(10)\n",
    "\n",
    "spark.sql(\"SELECT Substancia, Cast(SUM(QUANTIDADECOMERCIALIZADA) as DECIMAL(25,3)) as SomaQuantidadeComercializada_g \"\n",
    "          \"FROM arrecadacao WHERE UnidadeDeMedida = 'Gramas' GROUP BY(Substancia) ORDER BY SUM(QUANTIDADECOMERCIALIZADA) DESC\").show(10)\n",
    "\n",
    "spark.sql(\"SELECT Substancia, Cast(SUM(QUANTIDADECOMERCIALIZADA) as DECIMAL(25,3)) as SomaQuantidadeComercializada_kg \"\n",
    "          \"FROM arrecadacao WHERE UnidadeDeMedida = 'Kg' GROUP BY(Substancia) ORDER BY SUM(QUANTIDADECOMERCIALIZADA) DESC\").show(10)\n",
    "\n",
    "spark.sql(\"SELECT Substancia, Cast(SUM(QUANTIDADECOMERCIALIZADA) as DECIMAL(25,3)) as SomaQuantidadeComercializada_K \"\n",
    "          \"FROM arrecadacao WHERE UnidadeDeMedida = 'Quilates' GROUP BY(Substancia) ORDER BY SUM(QUANTIDADECOMERCIALIZADA) DESC\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Table or view not found: arrecadacao; line 1 pos 14'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o57.sql.\n: org.apache.spark.sql.AnalysisException: Table or view not found: arrecadacao; line 1 pos 14\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:47)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:798)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:750)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$6.applyOrElse(Analyzer.scala:780)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$6.applyOrElse(Analyzer.scala:773)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$3(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$1(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:84)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$2(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$1(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:84)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$2(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$1(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:84)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:773)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:719)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:87)\n\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n\tat scala.collection.immutable.List.foldLeft(List.scala:89)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:76)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:121)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:48)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:643)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.sql.catalyst.analysis.NoSuchTableException: Table or view 'arrecadacao' not found in database 'default';\n\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalog.requireTableExists(ExternalCatalog.scala:48)\n\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalog.requireTableExists$(ExternalCatalog.scala:46)\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.requireTableExists(InMemoryCatalog.scala:45)\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.getTable(InMemoryCatalog.scala:326)\n\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.getTable(ExternalCatalogWithListener.scala:138)\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.lookupRelation(SessionCatalog.scala:706)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:795)\n\t... 59 more\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ff0129c01ac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mInvestigando\u001b[0m \u001b[0mos\u001b[0m \u001b[0mminérios\u001b[0m \u001b[0mem\u001b[0m \u001b[0mque\u001b[0m \u001b[0ma\u001b[0m \u001b[0mquantidade\u001b[0m \u001b[0mde\u001b[0m \u001b[0mmedida\u001b[0m \u001b[0mé\u001b[0m \u001b[0mkg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m '''\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT * FROM arrecadacao WHERE UnidadeDeMedida like '%Quilo%' \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \"\"\"\n\u001b[0;32m--> 767\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Table or view not found: arrecadacao; line 1 pos 14'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Investigando os minérios em que a quantidade de medida é kg\n",
    "'''\n",
    "spark.sql(\"SELECT * FROM arrecadacao WHERE UnidadeDeMedida like '%Quilo%' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Table or view not found: arrecadacao; line 1 pos 272'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o57.sql.\n: org.apache.spark.sql.AnalysisException: Table or view not found: arrecadacao; line 1 pos 272\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:47)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:798)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:750)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$6.applyOrElse(Analyzer.scala:780)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$6.applyOrElse(Analyzer.scala:773)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$3(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$1(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:84)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$2(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$1(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:84)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$2(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$1(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:84)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$2(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$1(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:84)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:773)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:719)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:87)\n\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n\tat scala.collection.immutable.List.foldLeft(List.scala:89)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:76)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:121)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:48)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:643)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.sql.catalyst.analysis.NoSuchTableException: Table or view 'arrecadacao' not found in database 'default';\n\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalog.requireTableExists(ExternalCatalog.scala:48)\n\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalog.requireTableExists$(ExternalCatalog.scala:46)\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.requireTableExists(InMemoryCatalog.scala:45)\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.getTable(InMemoryCatalog.scala:326)\n\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.getTable(ExternalCatalogWithListener.scala:138)\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.lookupRelation(SessionCatalog.scala:706)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:795)\n\t... 68 more\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-daec9a1a799d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mInvestigando\u001b[0m \u001b[0mos\u001b[0m \u001b[0mminérios\u001b[0m \u001b[0mque\u001b[0m \u001b[0mpossuem\u001b[0m \u001b[0mmais\u001b[0m \u001b[0mimposto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m '''\n\u001b[0;32m----> 4\u001b[0;31m spark.sql(\"SELECT Substancia, Cast(SUM(QUANTIDADECOMERCIALIZADA) as DECIMAL(25,3)) as SomaQuantidadeComercializada, \"\n\u001b[0m\u001b[1;32m      5\u001b[0m           \u001b[0;34m\"CAST(SUM(ValorRecolhido) as DECIMAL(25,3)) as mediaValorRecolhido, CAST(SUM(ValorRecolhido)/SUM(QuantidadeComercializada) as DECIMAL(10,2)) as impostoPorTonelada \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \"FROM arrecadacao WHERE UnidadeDeMedida = 'Toneladas' GROUP BY(Substancia) ORDER BY impostoPorTonelada DESC\").show(10)\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \"\"\"\n\u001b[0;32m--> 767\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Table or view not found: arrecadacao; line 1 pos 272'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Investigando os minérios que possuem mais imposto\n",
    "'''\n",
    "spark.sql(\"SELECT Substancia, Cast(SUM(QUANTIDADECOMERCIALIZADA) as DECIMAL(25,3)) as SomaQuantidadeComercializada, \"\n",
    "          \"CAST(SUM(ValorRecolhido) as DECIMAL(25,3)) as mediaValorRecolhido, CAST(SUM(ValorRecolhido)/SUM(QuantidadeComercializada) as DECIMAL(10,2)) as impostoPorTonelada \"\n",
    "          \"FROM arrecadacao WHERE UnidadeDeMedida = 'Toneladas' GROUP BY(Substancia) ORDER BY impostoPorTonelada DESC\").show(10)\n",
    "\n",
    "spark.sql(\"SELECT Substancia, Cast(SUM(QUANTIDADECOMERCIALIZADA) as DECIMAL(25,3)) as SomaQuantidadeComercializada, \"\n",
    "          \"CAST(SUM(ValorRecolhido) as DECIMAL(25,3)) as mediaValorRecolhido, CAST(SUM(ValorRecolhido)/SUM(QuantidadeComercializada) as DECIMAL(10,2)) as impostoPorQuilate \"\n",
    "          \"FROM arrecadacao WHERE UnidadeDeMedida = 'Quilates' GROUP BY(Substancia) ORDER BY impostoPorQuilate DESC\").show(10)\n",
    "\n",
    "spark.sql(\"SELECT Substancia, Cast(SUM(QUANTIDADECOMERCIALIZADA) as DECIMAL(25,3)) as SomaQuantidadeComercializada, \"\n",
    "          \"CAST(SUM(ValorRecolhido) as DECIMAL(25,3)) as mediaValorRecolhido, CAST(SUM(ValorRecolhido)/SUM(QuantidadeComercializada) as DECIMAL(10,2)) as impostoPorMetroQuad \"\n",
    "          \"FROM arrecadacao WHERE UnidadeDeMedida = 'Metros Quadrados' GROUP BY(Substancia) ORDER BY impostoPorMetroQuad DESC\").show(10)\n",
    "\n",
    "spark.sql(\"SELECT Substancia, Cast(SUM(QUANTIDADECOMERCIALIZADA) as DECIMAL(25,3)) as SomaQuantidadeComercializada, \"\n",
    "          \"CAST(SUM(ValorRecolhido) as DECIMAL(25,3)) as mediaValorRecolhido, CAST(SUM(ValorRecolhido)/SUM(QuantidadeComercializada) as DECIMAL(10,2)) as impostoPorMetroCub \"\n",
    "          \"FROM arrecadacao WHERE UnidadeDeMedida = 'Metros Cubicos' GROUP BY(Substancia) ORDER BY impostoPorMetroCub DESC\").show(10)\n",
    "\n",
    "spark.sql(\"SELECT Substancia, Cast(SUM(QUANTIDADECOMERCIALIZADA) as DECIMAL(25,3)) as SomaQuantidadeComercializada, \"\n",
    "          \"CAST(SUM(ValorRecolhido) as DECIMAL(25,3)) as mediaValorRecolhido, CAST(SUM(ValorRecolhido)/SUM(QuantidadeComercializada) as DECIMAL(10,2)) as impostoPorLitro \"\n",
    "          \"FROM arrecadacao WHERE UnidadeDeMedida = 'Litros' GROUP BY(Substancia) ORDER BY impostoPorLitro DESC\").show(10)\n",
    "\n",
    "spark.sql(\"SELECT Substancia, Cast(SUM(QUANTIDADECOMERCIALIZADA) as DECIMAL(25,3)) as SomaQuantidadeComercializada, \"\n",
    "          \"CAST(SUM(ValorRecolhido) as DECIMAL(25,3)) as mediaValorRecolhido, CAST(SUM(ValorRecolhido)/SUM(QuantidadeComercializada) as DECIMAL(10,2)) as impostoPorGramas \"\n",
    "          \"FROM arrecadacao WHERE UnidadeDeMedida = 'Gramas' GROUP BY(Substancia) ORDER BY impostoPorGramas DESC\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pib = spark.read.csv('gs://soulcode-mineracao/tratados/pib.csv', inferSchema=True, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pib.createOrReplaceTempView('pib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ano',\n",
       " 'id_municipio',\n",
       " 'pib',\n",
       " 'impostos_liquidos',\n",
       " 'va',\n",
       " 'va_agropecuaria',\n",
       " 'va_industria',\n",
       " 'va_servicos',\n",
       " 'va_adespss']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pib.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----------------------+-------------+--------------------+-----------------+----------------+---------------+\n",
      "| ano|     sum(pib)|sum(impostos_liquidos)|      sum(va)|sum(va_agropecuaria)|sum(va_industria)|sum(va_servicos)|sum(va_adespss)|\n",
      "+----+-------------+----------------------+-------------+--------------------+-----------------+----------------+---------------+\n",
      "|2002|1488787276039|          218572609012|1270214667015|         81515198966|     334907570007|    644403214045|   209388684020|\n",
      "|2003|1717950386056|          247233152001|1470717233978|        105949164973|     396568543017|    732543684039|   235655841993|\n",
      "|2004|1957751224028|          295769100994|1661982123059|        110912703012|     475863218000|    815527583034|   259678618984|\n",
      "|2005|2170584502984|          327768754273|1842818402007|        100957547036|     524686244007|    922044704993|   295129905954|\n",
      "|2006|2409449916019|          360159937992|2049289978009|        105294010981|     567281406012|   1043094774978|   333619786031|\n",
      "|2007|2720262950930|          400734669993|2319528280985|        120151714997|     629071170992|   1193195220987|   377110173985|\n",
      "|2008|3109803096975|          483325381005|2626477715984|        142051181983|     717907186036|   1332296659026|   434222689025|\n",
      "|2009|3333039338988|          483277026373|2849762821989|        149212634996|     729222075014|   1484149305942|   487178806006|\n",
      "|2010|3885846999973|          583115331549|3302839999988|        159932000003|     904158000021|   1700905000023|   537844999954|\n",
      "|2011|4376381999975|          655953523727|3720460999970|        190023999999|    1011034000004|   1921343999999|   598059000017|\n",
      "|2012|4814760000022|          720529486876|4094259000014|        200694999998|    1065682000000|   2175781000015|   652101000005|\n",
      "|2013|5331618956621|          777875776445|4553760000020|        240289999980|    1131626000012|   2435656999995|   746187000027|\n",
      "|2014|5778952779987|          806232611218|4972734000025|        249975000006|    1183093999992|   2722856999957|   816808000006|\n",
      "|2015|5995786999978|          840203782484|5155601000043|        258966999940|    1160787000023|   2850259999964|   885586999951|\n",
      "|2016|6269327999976|          849534546163|5419821999979|        306655000002|    1150720000012|   3017325999991|   945120999987|\n",
      "|2017|6585479000016|          913552999997|5671925999993|        302970999989|    1197799999969|   3170179999971|  1000974999971|\n",
      "|2018|7004140999992|          992990999970|6011149999954|        309611000012|    1313209999995|   3342943999947|  1045385000005|\n",
      "+----+-------------+----------------------+-------------+--------------------+-----------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT ano, SUM(pib), SUM(impostos_liquidos), sum(va), sum(va_agropecuaria), sum(va_industria), sum(va_servicos), sum(va_adespss) FROM pib GROUP BY ano ORDER BY ano\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+----------------------+-------------+--------------------+-----------------+----------------+---------------+\n",
      "|id_municipio|     sum(pib)|sum(impostos_liquidos)|      sum(va)|sum(va_agropecuaria)|sum(va_industria)|sum(va_servicos)|sum(va_adespss)|\n",
      "+------------+-------------+----------------------+-------------+--------------------+-----------------+----------------+---------------+\n",
      "|     3550308|7665059415725|         1393893909426|6271165506297|           358199113|     847621578137|   4952149715780|   471036013269|\n",
      "|     3304557|3688917912360|          830073114061|2858844798301|           795436389|     455037435209|   1899649121127|   503362805574|\n",
      "|     5300108|2454731764824|          330618608760|2124113156063|          8060086541|     127995157170|   1034273221201|   953784691149|\n",
      "|     4106902| 976174788039|          181891684423| 794283103619|           113572013|     172746483400|    537040891916|    84382156290|\n",
      "|     1302603| 824412695626|          166164551580| 658248144046|          2416851207|     293761955123|    278571483414|    83497854305|\n",
      "|     3106200|1017163739219|          151832354563| 865331384657|            18000537|     163610531011|    589253577363|   112449275749|\n",
      "|     3534401| 729592935805|          149231494538| 580361441270|             7766663|      44098141937|    506258894983|    29996637687|\n",
      "|     3505708| 557100871637|          146178094153| 410922777485|             2588886|      61410236687|    331075628500|    18434323404|\n",
      "|     3548708| 619027878016|          134769868718| 484258009294|            69115551|     180759736348|    269201455490|    34227701904|\n",
      "|     4314902| 777402011793|          122420325799| 654981685992|           284189073|      78532246420|    504437657479|    71727593017|\n",
      "|     3509502| 661327632403|          118098834637| 543228797763|          1156642102|     123887698476|    368125054898|    50059402290|\n",
      "|     3518800| 611133652722|          102122158763| 509011493962|           330910857|     149050907573|    305367089249|    54262586281|\n",
      "|     2611606| 572248782916|           97903028380| 474345754532|           373474278|      80464919370|    327592356226|    65915004656|\n",
      "|     2927408| 683433192304|           95066981135| 588366211170|           416171385|      99535140151|    408120880867|    80294018765|\n",
      "|     2304400| 646666298666|           93938016388| 552728282276|           588845398|      95978451196|    371479907907|    84681077775|\n",
      "|     3205309| 308828042765|           92633254288| 216194788479|           142857286|      58168570257|    136951615244|    20931745692|\n",
      "|     3525904| 423879103729|           80172851582| 343706252147|          1151085116|      99124348578|    224405467877|    19025350578|\n",
      "|     3106705| 316800632293|           74700068616| 242100563678|           187795670|     117255832682|    103162186575|    21494748749|\n",
      "|     4125506| 273319770614|           71469730181| 201850040434|          3619822480|      94565608300|     90282947504|    13381662149|\n",
      "|     5208707| 517186125501|           68650928319| 448535197182|           503764544|      85442483177|    302199219549|    60389729914|\n",
      "+------------+-------------+----------------------+-------------+--------------------+-----------------+----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT id_municipio, SUM(pib), SUM(impostos_liquidos), sum(va), sum(va_agropecuaria), sum(va_industria), sum(va_servicos), sum(va_adespss) FROM pib GROUP BY id_municipio ORDER BY SUM(impostos_liquidos) DESC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ano: integer (nullable = true)\n",
      " |-- id_municipio: integer (nullable = true)\n",
      " |-- pib: long (nullable = true)\n",
      " |-- impostos_liquidos: long (nullable = true)\n",
      " |-- va: long (nullable = true)\n",
      " |-- va_agropecuaria: long (nullable = true)\n",
      " |-- va_industria: long (nullable = true)\n",
      " |-- va_servicos: long (nullable = true)\n",
      " |-- va_adespss: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pib.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barragens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_barragens = spark.read.csv('gs://soulcode-mineracao/tratados/barragens.csv', inferSchema=True, header=True, encoding='utf-8')\n",
    "dfp_barragens = df_barragens.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Empreendedor</th>\n",
       "      <th>UF</th>\n",
       "      <th>Município</th>\n",
       "      <th>Categoria de Risco - CRI</th>\n",
       "      <th>Nível de Emergência</th>\n",
       "      <th>Tipo de Barragem de Mineração</th>\n",
       "      <th>Vida útil prevista da Barragem (anos)</th>\n",
       "      <th>Estrutura com o Objetivo de Contenção</th>\n",
       "      <th>Minério principal presente no reservatório</th>\n",
       "      <th>N pessoas afetadas a jusante em caso de rompimento da barragem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MOSAIC FERTILIZANTES P&amp;K LTDA.</td>\n",
       "      <td>SE</td>\n",
       "      <td>ROSÁRIO DO CATETE</td>\n",
       "      <td>Não se aplica</td>\n",
       "      <td>Sem emergência</td>\n",
       "      <td>Barragem/Barramento/Dique</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Rejeitos</td>\n",
       "      <td>Sais</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MINERACAO SAO FRANCISCO DE ASSIS LTDA</td>\n",
       "      <td>PA</td>\n",
       "      <td>SÃO FÉLIX DO XINGU</td>\n",
       "      <td>Não se aplica</td>\n",
       "      <td>Sem emergência</td>\n",
       "      <td>Barragem/Barramento/Dique</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rejeitos</td>\n",
       "      <td>Areia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAGNESITA MINERACAO S.A. Filial: MAGNESITA MIN...</td>\n",
       "      <td>BA</td>\n",
       "      <td>SANTALUZ</td>\n",
       "      <td>Não se aplica</td>\n",
       "      <td>Sem emergência</td>\n",
       "      <td>Barragem/Barramento/Dique</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Rejeitos</td>\n",
       "      <td>Cromita</td>\n",
       "      <td>875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAGNESITA MINERACAO S.A. Filial: MAGNESITA MIN...</td>\n",
       "      <td>BA</td>\n",
       "      <td>SANTALUZ</td>\n",
       "      <td>Não se aplica</td>\n",
       "      <td>Sem emergência</td>\n",
       "      <td>Barragem/Barramento/Dique</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Rejeitos</td>\n",
       "      <td>Cromita</td>\n",
       "      <td>1100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAGNESITA MINERACAO S.A. Filial: MAGNESITA MIN...</td>\n",
       "      <td>BA</td>\n",
       "      <td>SANTALUZ</td>\n",
       "      <td>Não se aplica</td>\n",
       "      <td>Sem emergência</td>\n",
       "      <td>Barragem/Barramento/Dique</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Rejeitos</td>\n",
       "      <td>Cromita</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Empreendedor  UF           Município  \\\n",
       "0                     MOSAIC FERTILIZANTES P&K LTDA.  SE   ROSÁRIO DO CATETE   \n",
       "1              MINERACAO SAO FRANCISCO DE ASSIS LTDA  PA  SÃO FÉLIX DO XINGU   \n",
       "2  MAGNESITA MINERACAO S.A. Filial: MAGNESITA MIN...  BA            SANTALUZ   \n",
       "3  MAGNESITA MINERACAO S.A. Filial: MAGNESITA MIN...  BA            SANTALUZ   \n",
       "4  MAGNESITA MINERACAO S.A. Filial: MAGNESITA MIN...  BA            SANTALUZ   \n",
       "\n",
       "  Categoria de Risco - CRI Nível de Emergência Tipo de Barragem de Mineração  \\\n",
       "0            Não se aplica      Sem emergência     Barragem/Barramento/Dique   \n",
       "1            Não se aplica      Sem emergência     Barragem/Barramento/Dique   \n",
       "2            Não se aplica      Sem emergência     Barragem/Barramento/Dique   \n",
       "3            Não se aplica      Sem emergência     Barragem/Barramento/Dique   \n",
       "4            Não se aplica      Sem emergência     Barragem/Barramento/Dique   \n",
       "\n",
       "   Vida útil prevista da Barragem (anos)  \\\n",
       "0                                   34.0   \n",
       "1                                    NaN   \n",
       "2                                   14.0   \n",
       "3                                   14.0   \n",
       "4                                   14.0   \n",
       "\n",
       "  Estrutura com o Objetivo de Contenção  \\\n",
       "0                              Rejeitos   \n",
       "1                              Rejeitos   \n",
       "2                              Rejeitos   \n",
       "3                              Rejeitos   \n",
       "4                              Rejeitos   \n",
       "\n",
       "  Minério principal presente no reservatório  \\\n",
       "0                                       Sais   \n",
       "1                                      Areia   \n",
       "2                                    Cromita   \n",
       "3                                    Cromita   \n",
       "4                                    Cromita   \n",
       "\n",
       "   N pessoas afetadas a jusante em caso de rompimento da barragem  \n",
       "0                                              100.0               \n",
       "1                                                NaN               \n",
       "2                                              875.0               \n",
       "3                                             1100.0               \n",
       "4                                             1125.0               "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp_barragens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_barragens = df_barragens.withColumnRenamed('N pessoas afetadas a jusante em caso de rompimento da barragem', 'nAfetadosRompimento')\\\n",
    "                           .withColumnRenamed('Estrutura com o Objetivo de Contenção', 'estruturaContencao')\\\n",
    "                           .withColumnRenamed('Vida útil prevista da Barragem (anos)', 'vidaUtilAnos')\\\n",
    "                           .withColumnRenamed('Nível de Emergência', 'nivelEmergencia')\\\n",
    "                           .withColumnRenamed('Categoria de Risco - CRI', 'categoriaRiscoCRI')\\\n",
    "                           .withColumnRenamed('Município', 'municipio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_barragens.createOrReplaceTempView('barragens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Empreendedor: string (nullable = true)\n",
      " |-- UF: string (nullable = true)\n",
      " |-- municipio: string (nullable = true)\n",
      " |-- categoriaRiscoCRI: string (nullable = true)\n",
      " |-- nivelEmergencia: string (nullable = true)\n",
      " |-- Tipo de Barragem de Mineração: string (nullable = true)\n",
      " |-- vidaUtilAnos: double (nullable = true)\n",
      " |-- estruturaContencao: string (nullable = true)\n",
      " |-- Minério principal presente no reservatório: string (nullable = true)\n",
      " |-- nAfetadosRompimento: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_barragens.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------+\n",
      "| UF|somaAfetadosRompimento|\n",
      "+---+----------------------+\n",
      "| MG|         1637078647.27|\n",
      "| PA|          208944531.94|\n",
      "| GO|           82920100.00|\n",
      "| BA|           44544955.00|\n",
      "| RO|           35757479.56|\n",
      "| SP|            9736054.56|\n",
      "| MT|            8293207.49|\n",
      "| AP|            1870800.00|\n",
      "| MS|            1333226.40|\n",
      "| TO|              39000.00|\n",
      "+---+----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Os 10 estados com maior número de habitantes com risco de serem afetados por rompimento de barragens\n",
    "'''\n",
    "\n",
    "spark.sql(\"SELECT UF, CAST(SUM(nAfetadosRompimento) as DECIMAL(30,2)) as somaAfetadosRompimento FROM barragens GROUP BY UF ORDER BY somaAfetadosRompimento DESC \").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+\n",
      "| UF|mediaVidaUtilAnos|\n",
      "+---+-----------------+\n",
      "| PI|             null|\n",
      "| PB|             null|\n",
      "| RO|             4.57|\n",
      "| MA|             5.33|\n",
      "| BA|             5.96|\n",
      "| RS|             6.60|\n",
      "| SC|            12.46|\n",
      "| AM|            12.67|\n",
      "| SP|            13.04|\n",
      "| AL|            14.00|\n",
      "| AP|            14.31|\n",
      "| MT|            14.98|\n",
      "| GO|            15.43|\n",
      "| MS|            17.56|\n",
      "| PA|            18.40|\n",
      "| TO|            22.17|\n",
      "| MG|            22.67|\n",
      "| PR|            24.67|\n",
      "| SE|            32.33|\n",
      "| RJ|            34.00|\n",
      "+---+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Verificando a vida média da vida útil das barragens por estado\n",
    "'''\n",
    "\n",
    "spark.sql(\"SELECT UF, CAST(AVG(vidaUtilAnos) as decimal(20,2)) as mediaVidaUtilAnos FROM barragens GROUP BY UF ORDER BY mediaVidaUtilAnos\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|   nivelEmergencia|\n",
      "+------------------+\n",
      "|    Sem emergência|\n",
      "|Emergência Nivel 3|\n",
      "|Emergência Nivel 2|\n",
      "|Emergência Nivel 1|\n",
      "+------------------+\n",
      "\n",
      "+-----------------+\n",
      "|categoriaRiscoCRI|\n",
      "+-----------------+\n",
      "|             Alta|\n",
      "|            Média|\n",
      "|    Não se aplica|\n",
      "|            Baixa|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DISTINCT nivelEmergencia FROM barragens\").show()\n",
    "\n",
    "spark.sql(\"SELECT DISTINCT categoriaRiscoCRI FROM barragens\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------+-----------------------------------------------+\n",
      "| UF|numBarragensSemEmergencia|CAST(sum(nAfetadosRompimento) AS DECIMAL(30,2))|\n",
      "+---+-------------------------+-----------------------------------------------+\n",
      "| MG|                      314|                                  1530238706.12|\n",
      "| MT|                      141|                                     6193207.49|\n",
      "| PA|                      113|                                   208876031.94|\n",
      "| BA|                       81|                                    44544955.00|\n",
      "| SP|                       67|                                     9736054.56|\n",
      "| RO|                       36|                                    35757479.56|\n",
      "| GO|                       22|                                    82920100.00|\n",
      "| MS|                       18|                                     1333226.40|\n",
      "| AP|                       17|                                     1870800.00|\n",
      "| AM|                       15|                                        1400.00|\n",
      "| SC|                       14|                                       30600.00|\n",
      "| TO|                        7|                                       39000.00|\n",
      "| RS|                        6|                                         200.00|\n",
      "| SE|                        3|                                         100.00|\n",
      "| MA|                        3|                                           null|\n",
      "| PR|                        3|                                           null|\n",
      "| PI|                        2|                                           null|\n",
      "| RJ|                        2|                                        1100.00|\n",
      "| PB|                        1|                                           null|\n",
      "| AL|                        1|                                           null|\n",
      "+---+-------------------------+-----------------------------------------------+\n",
      "\n",
      "+---+-----------------------+-----------------------------------------------+\n",
      "| UF|numBarragensEmergencia3|CAST(sum(nAfetadosRompimento) AS DECIMAL(30,2))|\n",
      "+---+-----------------------+-----------------------------------------------+\n",
      "| MG|                      3|                                    29339136.71|\n",
      "+---+-----------------------+-----------------------------------------------+\n",
      "\n",
      "+---+-----------------------+-----------------------------------------------+\n",
      "| UF|numBarragensEmergencia2|CAST(sum(nAfetadosRompimento) AS DECIMAL(30,2))|\n",
      "+---+-----------------------+-----------------------------------------------+\n",
      "| MG|                      7|                                    35542774.44|\n",
      "+---+-----------------------+-----------------------------------------------+\n",
      "\n",
      "+---+-----------------------+-----------------------------------------------+\n",
      "| UF|numBarragensEmergencia1|CAST(sum(nAfetadosRompimento) AS DECIMAL(30,2))|\n",
      "+---+-----------------------+-----------------------------------------------+\n",
      "| MG|                     26|                                    41958030.00|\n",
      "| MT|                      2|                                     2100000.00|\n",
      "| PA|                      1|                                       68500.00|\n",
      "| AP|                      1|                                           null|\n",
      "+---+-----------------------+-----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT UF, COUNT(nivelEmergencia) as numBarragensSemEmergencia, CAST(SUM(nAfetadosRompimento) as DECIMAL(30,2)) FROM barragens WHERE nivelEmergencia = 'Sem emergência' GROUP BY UF ORDER BY numBarragensSemEmergencia DESC \").show()\n",
    "\n",
    "spark.sql(\"SELECT UF, COUNT(nivelEmergencia) as numBarragensEmergencia3, CAST(SUM(nAfetadosRompimento) as DECIMAL(30,2)) FROM barragens WHERE nivelEmergencia = 'Emergência Nivel 3' GROUP BY UF ORDER BY numBarragensEmergencia3 DESC \").show()\n",
    "\n",
    "spark.sql(\"SELECT UF, COUNT(nivelEmergencia) as numBarragensEmergencia2, CAST(SUM(nAfetadosRompimento) as DECIMAL(30,2)) FROM barragens WHERE nivelEmergencia = 'Emergência Nivel 2' GROUP BY UF ORDER BY numBarragensEmergencia2 DESC \").show()\n",
    "\n",
    "spark.sql(\"SELECT UF, COUNT(nivelEmergencia) as numBarragensEmergencia1, CAST(SUM(nAfetadosRompimento) as DECIMAL(30,2)) FROM barragens WHERE nivelEmergencia = 'Emergência Nivel 1' GROUP BY UF ORDER BY numBarragensEmergencia1 DESC \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+-----------------+------------------+\n",
      "| UF|           municipio|        Empreendedor|categoriaRiscoCRI|   nivelEmergencia|\n",
      "+---+--------------------+--------------------+-----------------+------------------+\n",
      "| MG|           RIO ACIMA|Massa Falida de M...|             Alta|Emergência Nivel 1|\n",
      "| MG|           RIO ACIMA|Massa Falida de M...|             Alta|Emergência Nivel 1|\n",
      "| AP|PEDRA BRANCA DO A...|DEV MINERACAO S.A...|             Alta|Emergência Nivel 1|\n",
      "| MT|              POCONÉ|   NORMA ARGES OLIVA|             Alta|Emergência Nivel 1|\n",
      "| MT|NOSSA SENHORA DO ...|     SERGIO DA SILVA|             Alta|Emergência Nivel 1|\n",
      "| MT|              POCONÉ|João de Pinho Nov...|             Alta|    Sem emergência|\n",
      "| MT|              POCONÉ|Ulisses José Dorileo|             Alta|    Sem emergência|\n",
      "| MG|           NOVA LIMA|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|     BARÃO DE COCAIS|           VALE S.A.|             Alta|Emergência Nivel 3|\n",
      "| MG|     BARÃO DE COCAIS|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|          OURO PRETO|           VALE S.A.|             Alta|Emergência Nivel 2|\n",
      "| MG|          OURO PRETO|           VALE S.A.|             Alta|Emergência Nivel 2|\n",
      "| MG|          OURO PRETO|           VALE S.A.|             Alta|Emergência Nivel 3|\n",
      "| MG|          OURO PRETO|           VALE S.A.|             Alta|Emergência Nivel 2|\n",
      "| MG|           NOVA LIMA|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|           NOVA LIMA|           VALE S.A.|             Alta|Emergência Nivel 2|\n",
      "| MG|           NOVA LIMA|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|           ITABIRITO|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|           NOVA LIMA|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|           NOVA LIMA|           VALE S.A.|             Alta|Emergência Nivel 3|\n",
      "| MG|SÃO GONÇALO DO RI...|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|     BARÃO DE COCAIS|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| PA|              MARABÁ|BURITIRAMA MINERA...|             Alta|Emergência Nivel 1|\n",
      "| MG|          ITATIAIUÇU|ARCELORMITTAL BRA...|             Alta|Emergência Nivel 2|\n",
      "| MG|          OURO PRETO|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|           BELO VALE|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|           NOVA LIMA|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|           NOVA LIMA|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|           NOVA LIMA|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|           RIO ACIMA|MINERIOS NACIONAL...|             Alta|Emergência Nivel 2|\n",
      "| MT|NOSSA SENHORA DO ...|JOSE MARIA OTAVIO...|             Alta|    Sem emergência|\n",
      "| MG|             MARIANA|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|         CATAS ALTAS|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|             MARIANA|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|          OURO PRETO|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|             MARIANA|           VALE S.A.|             Alta|Emergência Nivel 2|\n",
      "| MG|             ITABIRA|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|             ITABIRA|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|             ITABIRA|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|          OURO PRETO|           VALE S.A.|             Alta|Emergência Nivel 1|\n",
      "| MG|          BRUMADINHO|EMICON MINERACAO ...|             Alta|Emergência Nivel 1|\n",
      "| MG|          BRUMADINHO|EMICON MINERACAO ...|             Alta|Emergência Nivel 1|\n",
      "| MG|          OURO PRETO|Topazio Imperial ...|             Alta|Emergência Nivel 1|\n",
      "+---+--------------------+--------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT UF, municipio, Empreendedor, categoriaRiscoCRI, nivelEmergencia FROM barragens WHERE nivelEmergencia <> 'Sem emergência' or (categoriaRiscoCRI = 'Alta')\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----------------+----------------------+\n",
      "| UF|           municipio|numBarragensRisco|somaAfetadosRompimento|\n",
      "+---+--------------------+-----------------+----------------------+\n",
      "| MG|          OURO PRETO|                8|           61805641.44|\n",
      "| MG|             MARIANA|                3|           23501100.00|\n",
      "| MG|           NOVA LIMA|                9|           13620258.00|\n",
      "| MG|     BARÃO DE COCAIS|                3|            7178241.71|\n",
      "| MT|              POCONÉ|                3|            2383500.00|\n",
      "| MT|NOSSA SENHORA DO ...|                2|            2100000.00|\n",
      "| MG|          BRUMADINHO|                2|             729000.00|\n",
      "| PA|              MARABÁ|                1|              68500.00|\n",
      "| MG|             ITABIRA|                3|               5100.00|\n",
      "| MG|           BELO VALE|                1|                500.00|\n",
      "| MG|         CATAS ALTAS|                1|                100.00|\n",
      "| MG|           ITABIRITO|                1|                  null|\n",
      "| MG|          ITATIAIUÇU|                1|                  null|\n",
      "| AP|PEDRA BRANCA DO A...|                1|                  null|\n",
      "| MG|SÃO GONÇALO DO RI...|                1|                  null|\n",
      "| MG|           RIO ACIMA|                3|                  null|\n",
      "+---+--------------------+-----------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Número de barragens em risco e de afetados pelo rompimento por município\n",
    "'''\n",
    "\n",
    "spark.sql(\"SELECT UF, municipio, COUNT(municipio) as numBarragensRisco, CAST(SUM(nAfetadosRompimento) as DECIMAL(30,2)) as somaAfetadosRompimento FROM barragens WHERE nivelEmergencia <> 'Sem emergência' or categoriaRiscoCRI = 'Alta' GROUP BY uf, municipio ORDER BY somaAfetadosRompimento DESC\").show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados_populacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados_populacao = spark.read.csv('gs://soulcode-mineracao/tratados/dados_populacao.csv', inferSchema=True, header=True, encoding='utf-8')\n",
    "dfp_dados_populacao = df_dados_populacao.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados_populacao.createOrReplaceTempView('dados_populacao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Parte_SparkSQL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}