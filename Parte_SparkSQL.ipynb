{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parte_SparkSQL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-GDQpY0-m-m"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Cria ou substitui uma visão temporária para o DataFrame\n",
        "\n",
        "O tempo de vida dessa tabela temporária está vinculado à \n",
        "SparkSession que foi usada para criar o DataFrame.\n",
        "\n",
        "'''\n",
        "\n",
        "df_spark.createOrReplaceTempView('teste')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "> COUNT\n",
        "Contando a quantidade de linhas do Dataframe\n",
        "'''\n",
        "spark.sql('''SELECT COUNT (*)\n",
        "          FROM teste\n",
        "          ''').show()"
      ],
      "metadata": {
        "id": "-_hGe-1o_N8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "> DISTINCT\n",
        "Consultando apenas os valores distintos\n",
        "Aplicando, como exemplo, a coluna 'Ano'.\n",
        "'''\n",
        "\n",
        "spark.sql('''SELECT DISTINCT Ano\n",
        "          FROM teste\n",
        "          ORDER BY Ano\n",
        "          ''').show(30)"
      ],
      "metadata": {
        "id": "q44gaL-E_Qri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "> SOMA\n",
        "Consulta para a soma da quantidade comercializada por estado da view 'teste',\n",
        "agrupadas por estado e ordenadas do maior ao menor valor da soma da\n",
        "quantidade comercializada em ordem decrescente\n",
        "'''\n",
        "spark.sql('''SELECT UF, cast(SUM(QuantidadeComercializada) as DECIMAL(15,2)) as QuantidadeComercializada\n",
        "             FROM teste \n",
        "             GROUP BY UF\n",
        "             ORDER BY QuantidadeComercializada DESC;\n",
        "             ''').show(30)"
      ],
      "metadata": {
        "id": "nizP7IOj_atZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "> MÉDIA\n",
        "Consulta para a média da quantidade comercializada por estado da view 'teste',\n",
        "agrupadas por estado e ordenadas do maior ao menor valor da média da\n",
        "quantidade comercializada em ordem decrescente\n",
        "'''\n",
        "\n",
        "spark.sql('''SELECT UF, cast(AVG(QuantidadeComercializada) as DECIMAL(15,2)) as QuantidadeComercializada\n",
        "             FROM teste \n",
        "             GROUP BY UF\n",
        "             ORDER BY QuantidadeComercializada DESC;\n",
        "             ''').show(30)"
      ],
      "metadata": {
        "id": "xgV8SaLB_cnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "> SOMA\n",
        "Consulta para a soma do valor recolhido da view 'teste',\n",
        "agrupadas por ano e uf e ordenadas por ano e soma do\n",
        "valor recolhido em ordem decrescente\n",
        "'''\n",
        "\n",
        "spark.sql('''SELECT Ano, UF, cast(SUM(ValorRecolhido) as DECIMAL(15,2)) as ValorRecolhido\n",
        "             FROM teste \n",
        "             GROUP BY Ano, UF\n",
        "             ORDER BY Ano, ValorRecolhido DESC;\n",
        "             ''').show(200)"
      ],
      "metadata": {
        "id": "l0E6gYXA_hjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "> MÉDIA\n",
        "Consulta para a média do valor recolhido da view 'teste',\n",
        "agrupadas por ano e uf e ordenadas por ano e média do\n",
        "valor recolhido em ordem decrescente\n",
        "'''\n",
        "\n",
        "spark.sql('''SELECT Ano, UF, cast(AVG(ValorRecolhido) as DECIMAL(15,2)) as ValorRecolhido\n",
        "             FROM teste \n",
        "             GROUP BY Ano, UF\n",
        "             ORDER BY Ano, ValorRecolhido DESC;\n",
        "             ''').show(200)"
      ],
      "metadata": {
        "id": "jTZvIDwM_l-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IKShaJrr_m2N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}